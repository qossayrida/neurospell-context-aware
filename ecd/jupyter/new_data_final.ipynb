{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-31T11:39:51.096075100Z",
     "start_time": "2025-05-31T11:39:38.146842800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded characters: ABCDEFGHIJKLMNOPQRSTUVWXYZ123456789_\n",
      "\n",
      "Loading training data from: ../data/Contributor_I_Train.mat\n",
      "Number of trials based on Signal array: 85\n",
      "Extracted Target Character String (length 85): EAEVQTDOJG8RBRGONCEDHCTUIDBPUHMEM6OUXOCFOUKWA4VJEF...\n",
      "TargetChar string length matches number of signal trials.\n",
      "\n",
      "Train Data Info (Initial):\n",
      "  Signals shape: (85, 7794, 64)\n",
      "  Target Characters String Length: 85\n",
      "  Contributor: I\n",
      "  Sampling Frequency (initial): 240\n",
      "\n",
      "Applying Butterworth filter...\n",
      "Filtering complete.\n",
      "\n",
      "Downsampling signals from 240Hz to 120Hz...\n",
      "# Samples of EEG signals before downsampling: 7794\n",
      "# Samples of EEG signals after downsampling: 3897\n",
      "Downsampling complete.\n",
      "\n",
      "Extracting features and grouping by character...\n",
      "\n",
      "Feature extraction and grouping complete.\n",
      "\n",
      "--- Verification --- \n",
      "Number of samples per character:\n",
      "Character \t'A': 360 samples\n",
      "Character \t'B': 540 samples\n",
      "Character \t'C': 540 samples\n",
      "Character \t'D': 720 samples\n",
      "Character \t'E': 1440 samples\n",
      "Character \t'F': 360 samples\n",
      "Character \t'G': 360 samples\n",
      "Character \t'H': 720 samples\n",
      "Character \t'I': 540 samples\n",
      "Character \t'J': 360 samples\n",
      "Character \t'K': 540 samples\n",
      "Character \t'L': 360 samples\n",
      "Character \t'M': 360 samples\n",
      "Character \t'N': 360 samples\n",
      "Character \t'O': 1620 samples\n",
      "Character \t'P': 360 samples\n",
      "Character \t'Q': 540 samples\n",
      "Character \t'R': 900 samples\n",
      "Character \t'S': 0 samples\n",
      "Character \t'T': 720 samples\n",
      "Character \t'U': 900 samples\n",
      "Character \t'V': 360 samples\n",
      "Character \t'W': 540 samples\n",
      "Character \t'X': 360 samples\n",
      "Character \t'Y': 360 samples\n",
      "Character \t'Z': 360 samples\n",
      "Character \t'1': 0 samples\n",
      "Character \t'2': 0 samples\n",
      "Character \t'3': 0 samples\n",
      "Character \t'4': 180 samples\n",
      "Character \t'5': 0 samples\n",
      "Character \t'6': 180 samples\n",
      "Character \t'7': 0 samples\n",
      "Character \t'8': 180 samples\n",
      "Character \t'9': 0 samples\n",
      "Character \t'_': 180 samples\n",
      "\n",
      "Total samples collected across all characters: 15300\n",
      "\n",
      "--- Samples for Character 'A' (First 5) ---\n",
      "Printing the first 2 samples for character \t'E\t':\n",
      "\n",
      "--- Sample 1 for \t'E\t' (Shape: (78, 64)) ---\n",
      "[[-0.33714178 -0.9983543  -1.3232313  ... -1.1834699  -0.54913986\n",
      "  -2.146467  ]\n",
      " [-0.4871011  -0.9940677  -1.1646951  ... -1.0431285  -0.55491173\n",
      "  -2.1276486 ]\n",
      " [-0.5778563  -0.9702029  -0.9978453  ... -0.8722612  -0.5385763\n",
      "  -2.0364172 ]\n",
      " ...\n",
      " [-1.0796474  -0.7509957  -0.81012434 ... -1.5100384  -1.3592697\n",
      "  -1.2251195 ]\n",
      " [-1.0141852  -0.7882366  -0.8428319  ... -1.518697   -1.2910079\n",
      "  -1.3577971 ]\n",
      " [-0.97403663 -0.86051106 -0.94864607 ... -1.544415   -1.2291203\n",
      "  -1.4459875 ]]\n",
      "\n",
      "--- Sample 2 for \t'E\t' (Shape: (78, 64)) ---\n",
      "[[ 0.10983302 -0.5912167  -0.13849093 ...  1.2149168   1.2025372\n",
      "   0.03397316]\n",
      " [ 0.25884238 -0.40057978  0.04210157 ...  1.1914978   1.2291273\n",
      "   0.17662953]\n",
      " [ 0.43082425 -0.16021492  0.26143023 ...  1.1193072   1.2058557\n",
      "   0.27885613]\n",
      " ...\n",
      " [-0.6707997  -0.16460213  0.14333405 ... -0.06619231 -0.4230349\n",
      "  -0.9840886 ]\n",
      " [-0.68862873 -0.17394924  0.05029703 ... -0.15256847 -0.52998257\n",
      "  -1.2219926 ]\n",
      " [-0.7004211  -0.17817384 -0.06943762 ... -0.23664352 -0.6175329\n",
      "  -1.4326991 ]]\n",
      "\n",
      "--- Non-zero Samples Check ---\n",
      "A  B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  T  U  V  W  X  Y  Z  4  6  8  _  \n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal\n",
    "import os\n",
    "\n",
    "# Define a dummy print_data if DataCraft is not available/needed\n",
    "def print_data(signals, words_string, contributor, freq):\n",
    "    print(f\"  Signals shape: {signals.shape}\")\n",
    "    print(f\"  Target Characters String Length: {len(words_string) if isinstance(words_string, str) else 'N/A'}\")\n",
    "    print(f\"  Contributor: {contributor}\")\n",
    "    print(f\"  Sampling Frequency (initial): {freq}\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Configuration ---\n",
    "contributor_selected = \"I\"\n",
    "contributor_train_file_path = f\"../data/Contributor_{contributor_selected}_Train.mat\"\n",
    "characters_file_path = \"../data/characters.txt\"\n",
    "channels = list(range(64))\n",
    "initial_sampling_frequency = 240\n",
    "down_sampling_frequency = 120\n",
    "WINDOW_DURATION = 650 # ms\n",
    "\n",
    "# --- File Checks ---\n",
    "if not os.path.exists(contributor_train_file_path):\n",
    "    print(f\"Error: Train data file not found at {contributor_train_file_path}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    with open(characters_file_path, \"r\") as f:\n",
    "        characters = f.read().strip()\n",
    "    print(f\"Loaded characters: {characters}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Characters file not found at {characters_file_path}\")\n",
    "    exit()\n",
    "\n",
    "# --- Load Data ---\n",
    "print(f\"\\nLoading training data from: {contributor_train_file_path}\")\n",
    "data_train = loadmat(contributor_train_file_path)\n",
    "signals_train = data_train[\"Signal\"] # Shape: (Trials, Samples, Channels)\n",
    "flashing_train = data_train[\"Flashing\"]\n",
    "stimulus_train = data_train[\"StimulusType\"]\n",
    "word_train_raw = data_train[\"TargetChar\"] # Expected: String of target chars\n",
    "\n",
    "# --- Data Consistency Checks & Target Character Extraction ---\n",
    "num_signal_trials = signals_train.shape[0]\n",
    "print(f\"Number of trials based on Signal array: {num_signal_trials}\")\n",
    "\n",
    "# Extract the target character string robustly\n",
    "target_char_string = None\n",
    "if isinstance(word_train_raw, np.ndarray):\n",
    "    if word_train_raw.size == 1:\n",
    "        target_char_string = str(word_train_raw.item()).strip()\n",
    "    else:\n",
    "        # Handle unexpected array shape if necessary\n",
    "        print(f\"Warning: Unexpected shape for TargetChar: {word_train_raw.shape}. Trying to flatten.\")\n",
    "        try:\n",
    "            target_char_string = \"\".join(map(str, word_train_raw.flatten()))\n",
    "        except Exception as e:\n",
    "             print(f\"Error processing TargetChar array: {e}\")\n",
    "elif isinstance(word_train_raw, str):\n",
    "    target_char_string = word_train_raw.strip()\n",
    "else:\n",
    "    print(f\"Error: Unexpected type for TargetChar: {type(word_train_raw)}\")\n",
    "\n",
    "if target_char_string is None:\n",
    "    print(\"Error: Could not extract target character string. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Extracted Target Character String (length {len(target_char_string)}): {target_char_string[:50]}...\") # Print first 50 chars\n",
    "\n",
    "# Verify length consistency\n",
    "if len(target_char_string) != num_signal_trials:\n",
    "    print(f\"Error: Length of TargetChar string ({len(target_char_string)}) does not match number of trials in Signal ({num_signal_trials}). Please check data integrity.\")\n",
    "    # Decide whether to exit or proceed with min length\n",
    "    # For now, let's proceed but use the minimum length to avoid index errors\n",
    "    print(\"Warning: Proceeding with minimum of the two lengths for processing.\")\n",
    "    trials_to_process = min(len(target_char_string), num_signal_trials)\n",
    "else:\n",
    "    trials_to_process = num_signal_trials\n",
    "    print(\"TargetChar string length matches number of signal trials.\")\n",
    "\n",
    "print(\"\\nTrain Data Info (Initial):\")\n",
    "print_data(signals_train, target_char_string, contributor_selected, initial_sampling_frequency)\n",
    "\n",
    "# --- Butterworth Filter ---\n",
    "print(\"\\nApplying Butterworth filter...\")\n",
    "sampling_frequency = initial_sampling_frequency\n",
    "b, a = signal.butter(4, [0.1 / sampling_frequency, 20 / sampling_frequency], \"bandpass\")\n",
    "for trial in range(num_signal_trials): # Filter all signal trials\n",
    "    try:\n",
    "        signals_train[trial, :, :] = signal.filtfilt(b, a, signals_train[trial, :, :], axis=0)\n",
    "    except IndexError:\n",
    "        print(f\"Error: IndexError during filtering trial {trial}. Check signal dimensions.\")\n",
    "        continue\n",
    "print(\"Filtering complete.\")\n",
    "\n",
    "# --- Down-sampling ---\n",
    "print(f\"\\nDownsampling signals from {initial_sampling_frequency}Hz to {down_sampling_frequency}Hz...\")\n",
    "SCALE_FACTOR = round(initial_sampling_frequency / down_sampling_frequency)\n",
    "sampling_frequency = down_sampling_frequency\n",
    "\n",
    "print(f\"# Samples of EEG signals before downsampling: {signals_train.shape[1]}\")\n",
    "try:\n",
    "    signals_train = signals_train[:, ::SCALE_FACTOR, :]\n",
    "    flashing_train = flashing_train[:, ::SCALE_FACTOR]\n",
    "    stimulus_train = stimulus_train[:, ::SCALE_FACTOR]\n",
    "except IndexError as e:\n",
    "    print(f\"Error during downsampling: {e}. Check array dimensions after filtering.\")\n",
    "    exit()\n",
    "print(f\"# Samples of EEG signals after downsampling: {signals_train.shape[1]}\")\n",
    "print(\"Downsampling complete.\")\n",
    "\n",
    "# --- Feature Extraction & Grouping ---\n",
    "print(\"\\nExtracting features and grouping by character...\")\n",
    "N_CHANNELS = signals_train.shape[2]\n",
    "WINDOW_SAMPLES = round(sampling_frequency * (WINDOW_DURATION / 1000))\n",
    "SAMPLES_PER_TRIAL = signals_train.shape[1]\n",
    "\n",
    "samples = {char: [] for char in characters}\n",
    "\n",
    "# Loop through the determined number of trials to process\n",
    "for trial in range(trials_to_process):\n",
    "    # Get the target character for the current trial from the string\n",
    "    target_char = target_char_string[trial]\n",
    "\n",
    "    if target_char not in samples:\n",
    "        # This case should ideally not happen if characters.txt is correct\n",
    "        print(f\"Warning: Target character \t'{target_char}'\t from trial {trial} not found in characters.txt. Skipping this trial.\")\n",
    "        continue\n",
    "\n",
    "    # Ensure trial index is valid for other arrays (should be if trials_to_process is calculated correctly)\n",
    "    if trial >= flashing_train.shape[0] or trial >= stimulus_train.shape[0]:\n",
    "        print(f\"Warning: Trial index {trial} out of bounds for flashing/stimulus arrays. Stopping processing.\")\n",
    "        break\n",
    "\n",
    "    for sample_idx in range(SAMPLES_PER_TRIAL):\n",
    "        is_flash_start = False\n",
    "        try:\n",
    "            # Check bounds for flashing_train access\n",
    "            if sample_idx >= flashing_train.shape[1]:\n",
    "                 # print(f\"Warning: Sample index {sample_idx} exceeds flashing_train length ({flashing_train.shape[1]}) at trial {trial}. Stopping sample loop.\")\n",
    "                 break\n",
    "\n",
    "            if sample_idx == 0 and flashing_train[trial, sample_idx] == 1:\n",
    "                is_flash_start = True\n",
    "            elif sample_idx > 0:\n",
    "                 # Check bounds for previous sample index\n",
    "                 if sample_idx - 1 >= flashing_train.shape[1]:\n",
    "                     # print(f\"Warning: Previous sample index {sample_idx-1} exceeds flashing_train length at trial {trial}. Stopping sample loop.\")\n",
    "                     break\n",
    "                 if flashing_train[trial, sample_idx - 1] == 0 and flashing_train[trial, sample_idx] == 1:\n",
    "                     is_flash_start = True\n",
    "        except IndexError:\n",
    "            print(f\"Warning: IndexError accessing flashing_train at trial {trial}, sample {sample_idx}. Skipping sample.\")\n",
    "            continue # Skip this sample index\n",
    "\n",
    "        if is_flash_start:\n",
    "            lower_sample = sample_idx\n",
    "            upper_sample = sample_idx + WINDOW_SAMPLES\n",
    "\n",
    "            if upper_sample > SAMPLES_PER_TRIAL:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                if upper_sample > signals_train.shape[1]:\n",
    "                    continue\n",
    "                window = signals_train[trial, lower_sample:upper_sample, :]\n",
    "            except IndexError:\n",
    "                 print(f\"Warning: IndexError extracting window at trial {trial}, samples {lower_sample}:{upper_sample}. Skipping window.\")\n",
    "                 continue\n",
    "\n",
    "            if window.shape[0] != WINDOW_SAMPLES:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                if window.size == 0 or np.all(np.std(window, axis=0) == 0):\n",
    "                    normalized_window = window\n",
    "                else:\n",
    "                    normalized_window = scale(window, axis=0)\n",
    "            except ValueError as e:\n",
    "                 print(f\"Warning: ValueError during scaling window at trial {trial}, sample {sample_idx}: {e}. Skipping window.\")\n",
    "                 continue\n",
    "\n",
    "            samples[target_char].append(normalized_window)\n",
    "\n",
    "print(\"\\nFeature extraction and grouping complete.\")\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"\\n--- Verification --- \")\n",
    "print(\"Number of samples per character:\")\n",
    "total_samples_collected = 0\n",
    "for char, char_samples in samples.items():\n",
    "    count = len(char_samples)\n",
    "    print(f\"Character \t'{char}': {count} samples\")\n",
    "    total_samples_collected += count\n",
    "\n",
    "print(f\"\\nTotal samples collected across all characters: {total_samples_collected}\")\n",
    "\n",
    "\n",
    "# --- Print First 5 Samples for Character 'A' --- \n",
    "print(\"\\n--- Samples for Character 'A' (First 5) ---\")\n",
    "char_to_print = 'E'\n",
    "num_samples_to_print = 2\n",
    "\n",
    "if char_to_print in samples and samples[char_to_print]:\n",
    "    print(f\"Printing the first {min(num_samples_to_print, len(samples[char_to_print]))} samples for character \t'{char_to_print}\t':\")\n",
    "    for i, sample_data in enumerate(samples[char_to_print][:num_samples_to_print]):\n",
    "        print(f\"\\n--- Sample {i+1} for \t'{char_to_print}\t' (Shape: {sample_data.shape}) ---\")\n",
    "        # Set numpy print options for better readability if needed\n",
    "        # np.set_printoptions(threshold=np.inf) # To print the full array without truncation\n",
    "        print(sample_data)\n",
    "        # np.set_printoptions(threshold=1000) # Reset to default or another value if needed\n",
    "else:\n",
    "    print(f\"No samples found for character \t'{char_to_print}\t' or the list is empty.\")\n",
    "\n",
    "# print all char has the nonzero samples\n",
    "print(\"\\n--- Non-zero Samples Check ---\")\n",
    "for char, char_samples in samples.items():\n",
    "    count = len(char_samples)\n",
    "    if count > 0:\n",
    "        # print without new line\n",
    "            print(f\"{char} \", end=' ')\n",
    "\n",
    "\n",
    "print(\"\\nScript finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
