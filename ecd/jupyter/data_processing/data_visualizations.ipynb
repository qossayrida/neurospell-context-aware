{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Shape Analysis and Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "192cc4c5480b264c"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def load_sentence_eeg_prob_data(filepath=\"../../data/sentence_eeg_prob_data.pkl\"):\n",
    "    \"\"\"Loads the final processed data list from a pickle file.\"\"\"\n",
    "    print(f\"Attempting to load processed data from: {filepath}\")\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Error: File not found at {filepath}.\")\n",
    "        return None\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        print(\"Successfully loaded processed data.\")\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"Error: Loaded object is not a list (type: {type(data)}). Returning None.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during loading processed data: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_visualizations(data, output_dir=\"../../visualizations\"):\n",
    "    \"\"\"Creates and saves various visualizations of the data structure.\"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to visualize.\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating visualizations in {output_dir}...\")\n",
    "    \n",
    "    # 1. Character Distribution Bar Chart\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    char_counter = Counter([item['character'] for item in data])\n",
    "    chars = list(char_counter.keys())\n",
    "    counts = list(char_counter.values())\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_indices = np.argsort(counts)[::-1]\n",
    "    chars = [chars[i] for i in sorted_indices]\n",
    "    counts = [counts[i] for i in sorted_indices]\n",
    "    \n",
    "    plt.bar(range(len(chars)), counts, color='skyblue')\n",
    "    plt.xticks(range(len(chars)), chars, rotation=45)\n",
    "    plt.title('Character Distribution in Dataset', fontsize=16)\n",
    "    plt.xlabel('Characters', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/character_distribution.png\")\n",
    "    plt.close()\n",
    "    print(\"✓ Character distribution chart saved\")\n",
    "    \n",
    "    # 2. Sentence Length Histogram\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    unique_sentences = list(set([item['sentence'] for item in data]))\n",
    "    sentence_lengths = [len(sentence) for sentence in unique_sentences]\n",
    "    \n",
    "    plt.hist(sentence_lengths, bins=20, color='lightgreen', edgecolor='black')\n",
    "    plt.axvline(np.mean(sentence_lengths), color='red', linestyle='dashed', linewidth=2, \n",
    "                label=f'Mean: {np.mean(sentence_lengths):.2f}')\n",
    "    plt.title('Distribution of Sentence Lengths', fontsize=16)\n",
    "    plt.xlabel('Sentence Length (characters)', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/sentence_length_distribution.png\")\n",
    "    plt.close()\n",
    "    print(\"✓ Sentence length distribution chart saved\")\n",
    "    \n",
    "    # 3. Character Position in Sentences\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    char_positions = [item['char_idx_in_sentence'] for item in data]\n",
    "    \n",
    "    plt.hist(char_positions, bins=30, color='salmon', edgecolor='black')\n",
    "    plt.title('Distribution of Character Positions in Sentences', fontsize=16)\n",
    "    plt.xlabel('Character Position Index', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/character_position_distribution.png\")\n",
    "    plt.close()\n",
    "    print(\"✓ Character position distribution chart saved\")\n",
    "    \n",
    "    # 4. EEG Chunk Size Distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    chunk_sizes = [len(item['eeg_chunk']) for item in data if 'eeg_chunk' in item and item['eeg_chunk']]\n",
    "    \n",
    "    if chunk_sizes:\n",
    "        plt.hist(chunk_sizes, bins=20, color='lightblue', edgecolor='black')\n",
    "        plt.axvline(np.mean(chunk_sizes), color='red', linestyle='dashed', linewidth=2, \n",
    "                    label=f'Mean: {np.mean(chunk_sizes):.2f}')\n",
    "        plt.title('Distribution of EEG Chunk Sizes', fontsize=16)\n",
    "        plt.xlabel('Number of Samples in Chunk', fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/eeg_chunk_size_distribution.png\")\n",
    "        plt.close()\n",
    "        print(\"✓ EEG chunk size distribution chart saved\")\n",
    "    \n",
    "    # 5. EEG Sample Heatmap\n",
    "    sample_item = next((item for item in data if 'eeg_chunk' in item and item['eeg_chunk']), None)\n",
    "    if sample_item and sample_item['eeg_chunk']:\n",
    "        # Get the first sample from the chunk\n",
    "        sample = sample_item['eeg_chunk'][0]\n",
    "        \n",
    "        plt.figure(figsize=(14, 8))\n",
    "        sns.heatmap(sample.T, cmap='viridis', cbar_kws={'label': 'Amplitude'})\n",
    "        plt.title(f\"EEG Sample Heatmap for Character '{sample_item['character']}'\", fontsize=16)\n",
    "        plt.xlabel('Time Steps', fontsize=14)\n",
    "        plt.ylabel('Channels', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/eeg_sample_heatmap.png\")\n",
    "        plt.close()\n",
    "        print(\"✓ EEG sample heatmap saved\")\n",
    "        \n",
    "        # 6. EEG Sample Line Plot (for first few channels)\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        num_channels_to_plot = min(5, sample.shape[1])  # Plot up to 5 channels\n",
    "        for i in range(num_channels_to_plot):\n",
    "            plt.plot(sample[:, i], label=f'Channel {i+1}')\n",
    "        \n",
    "        plt.title(f\"EEG Signal for First {num_channels_to_plot} Channels\", fontsize=16)\n",
    "        plt.xlabel('Time Steps', fontsize=14)\n",
    "        plt.ylabel('Amplitude', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/eeg_sample_lineplot.png\")\n",
    "        plt.close()\n",
    "        print(\"✓ EEG sample line plot saved\")\n",
    "    \n",
    "    # 7. Next Character Probability Distribution\n",
    "    # Collect top predicted characters and their probabilities\n",
    "    top_chars = []\n",
    "    top_probs = []\n",
    "    \n",
    "    for item in data:\n",
    "        if 'next_char_probabilities' in item and item['next_char_probabilities']:\n",
    "            # Get the top predicted character\n",
    "            top_char, top_prob = max(item['next_char_probabilities'].items(), key=lambda x: x[1])\n",
    "            top_chars.append(top_char)\n",
    "            top_probs.append(top_prob)\n",
    "    \n",
    "    if top_chars:\n",
    "        # Create a histogram of top probabilities\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.hist(top_probs, bins=20, color='plum', edgecolor='black')\n",
    "        plt.title('Distribution of Top Prediction Probabilities', fontsize=16)\n",
    "        plt.xlabel('Probability', fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/top_probability_distribution.png\")\n",
    "        plt.close()\n",
    "        print(\"✓ Top probability distribution chart saved\")\n",
    "        \n",
    "        # Create a bar chart of top predicted characters\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        top_char_counter = Counter(top_chars)\n",
    "        chars = list(top_char_counter.keys())\n",
    "        counts = list(top_char_counter.values())\n",
    "        \n",
    "        # Sort by frequency\n",
    "        sorted_indices = np.argsort(counts)[::-1][:20]  # Top 20 characters\n",
    "        chars = [chars[i] for i in sorted_indices]\n",
    "        counts = [counts[i] for i in sorted_indices]\n",
    "        \n",
    "        plt.bar(range(len(chars)), counts, color='orchid')\n",
    "        plt.xticks(range(len(chars)), chars, rotation=45)\n",
    "        plt.title('Top 20 Most Frequently Predicted Next Characters', fontsize=16)\n",
    "        plt.xlabel('Characters', fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/top_predicted_characters.png\")\n",
    "        plt.close()\n",
    "        print(\"✓ Top predicted characters chart saved\")\n",
    "    \n",
    "    # 8. Data Structure Overview Diagram\n",
    "    # Create a visual representation of the data structure\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Define the structure components\n",
    "    components = [\n",
    "        \"Character\", \"Prefix\", \"Sentence\", \"Position Index\", \n",
    "        \"EEG Chunk\", \"Next Char Probabilities\"\n",
    "    ]\n",
    "    \n",
    "    # Define sizes (approximate relative memory usage)\n",
    "    if data and 'eeg_chunk' in data[0] and data[0]['eeg_chunk']:\n",
    "        eeg_size = sum(sample.nbytes for sample in data[0]['eeg_chunk'])\n",
    "        sizes = [\n",
    "            1,  # Character\n",
    "            len(data[0]['prefix']) if 'prefix' in data[0] else 0,  # Prefix\n",
    "            len(data[0]['sentence']) if 'sentence' in data[0] else 0,  # Sentence\n",
    "            4,  # Position Index (int)\n",
    "            eeg_size,  # EEG Chunk\n",
    "            len(data[0]['next_char_probabilities']) * 5 if 'next_char_probabilities' in data[0] else 0  # Next Char Probs\n",
    "        ]\n",
    "    else:\n",
    "        # Default sizes if no data\n",
    "        sizes = [1, 10, 20, 4, 1000, 50]\n",
    "    \n",
    "    # Normalize sizes for visualization\n",
    "    total = sum(sizes)\n",
    "    sizes = [size/total for size in sizes]\n",
    "    \n",
    "    # Create a horizontal bar chart\n",
    "    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#c2c2f0', '#ffb3e6']\n",
    "    y_pos = np.arange(len(components))\n",
    "    \n",
    "    plt.barh(y_pos, sizes, color=colors)\n",
    "    plt.yticks(y_pos, components)\n",
    "    plt.xlabel('Relative Size (normalized)', fontsize=14)\n",
    "    plt.title('Data Structure Components Overview', fontsize=16)\n",
    "    \n",
    "    # Add size annotations\n",
    "    for i, v in enumerate(sizes):\n",
    "        plt.text(v + 0.01, i, f\"{v:.2f}\", va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/data_structure_overview.png\")\n",
    "    plt.close()\n",
    "    print(\"✓ Data structure overview diagram saved\")\n",
    "    \n",
    "    # 9. Create a summary image with key statistics\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Collect key statistics\n",
    "    total_items = len(data)\n",
    "    unique_chars = len(char_counter)\n",
    "    unique_sentences_count = len(set([item['sentence'] for item in data]))\n",
    "    avg_sentence_length = np.mean([len(s) for s in set([item['sentence'] for item in data])])\n",
    "    \n",
    "    if sample_item and 'eeg_chunk' in sample_item and sample_item['eeg_chunk']:\n",
    "        sample = sample_item['eeg_chunk'][0]\n",
    "        eeg_shape = f\"{sample.shape[0]} × {sample.shape[1]}\"\n",
    "        avg_chunk_size = np.mean([len(item['eeg_chunk']) for item in data if 'eeg_chunk' in item and item['eeg_chunk']])\n",
    "    else:\n",
    "        eeg_shape = \"N/A\"\n",
    "        avg_chunk_size = 0\n",
    "    \n",
    "    # Create text for the summary\n",
    "    summary_text = (\n",
    "        \"DATA SHAPE SUMMARY\\n\"\n",
    "        \"==================\\n\\n\"\n",
    "        f\"Total Items: {total_items}\\n\"\n",
    "        f\"Unique Characters: {unique_chars}\\n\"\n",
    "        f\"Unique Sentences: {unique_sentences_count}\\n\"\n",
    "        f\"Avg. Sentence Length: {avg_sentence_length:.2f} chars\\n\"\n",
    "        f\"EEG Sample Shape: {eeg_shape}\\n\"\n",
    "        f\"Avg. Chunk Size: {avg_chunk_size:.2f} samples\\n\"\n",
    "    )\n",
    "    \n",
    "    plt.text(0.1, 0.5, summary_text, fontsize=14, family='monospace')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/data_summary.png\")\n",
    "    plt.close()\n",
    "    print(\"✓ Data summary image saved\")\n",
    "    \n",
    "    print(f\"\\nAll visualizations saved to {output_dir}/\")\n",
    "    return output_dir\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T18:24:47.898396900Z",
     "start_time": "2025-06-07T18:24:47.846780700Z"
    }
   },
   "id": "b0a3bddf2668f1b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and Analyze Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1aa0a163d445fb93"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load processed data from: ../../data/sentence_eeg_prob_data.pkl\n",
      "Successfully loaded processed data.\n",
      "Generating visualizations in ../../visualizations...\n",
      "✓ Character distribution chart saved\n",
      "✓ Sentence length distribution chart saved\n",
      "✓ Character position distribution chart saved\n",
      "✓ EEG chunk size distribution chart saved\n",
      "✓ EEG sample heatmap saved\n",
      "✓ EEG sample line plot saved\n",
      "✓ Top probability distribution chart saved\n",
      "✓ Top predicted characters chart saved\n",
      "✓ Data structure overview diagram saved\n",
      "✓ Data summary image saved\n",
      "\n",
      "All visualizations saved to ../../visualizations/\n",
      "\n",
      "To view the visualizations, check the files in the ../../visualizations directory.\n"
     ]
    }
   ],
   "source": [
    "# Try to load from the default path first\n",
    "data = load_sentence_eeg_prob_data()\n",
    "\n",
    "# If that fails, try the path in the current directory\n",
    "if data is None:\n",
    "    data = load_sentence_eeg_prob_data(\"sentence_eeg_prob_data.pkl\")\n",
    "\n",
    "if data:\n",
    "    # Create visualizations\n",
    "    output_dir = create_visualizations(data)\n",
    "    print(f\"\\nTo view the visualizations, check the files in the {output_dir} directory.\")\n",
    "else:\n",
    "    print(\"Failed to load data. Please check the file path.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T18:24:50.837417400Z",
     "start_time": "2025-06-07T18:24:47.883840100Z"
    }
   },
   "id": "723be49fdf1891c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
