{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c586d2047dd892ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Character Identity "
   ]
  },
  {
   "cell_type": "code",
   "id": "fc9a70b2966eb0ca",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-10T12:38:45.605837317Z",
     "start_time": "2026-01-10T12:38:45.433682616Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the parent directory to the path to import bundle\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal\n",
    "from bundle.DataCraft import * \n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Configuration ---\n",
    "contributors_to_process = [\"II\"]  # List of contributors to process\n",
    "characters_file_path = \"../../data/characters.txt\"  # Updated path\n",
    "channels = list(range(64))\n",
    "initial_sampling_frequency = 240\n",
    "down_sampling_frequency = 120\n",
    "WINDOW_DURATIONS = [650, 300]  # ms - for window sizes 78 and 36\n",
    "\n",
    "# --- File Checks & Character Loading ---\n",
    "try:\n",
    "    with open(characters_file_path, \"r\") as f:\n",
    "        characters = f.read().strip()\n",
    "    print(f\"Loaded characters from {characters_file_path}: {characters}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Characters file not found at {characters_file_path}\")\n",
    "    exit()\n",
    "\n",
    "# --- Initialize Combined Samples Dictionary for both window sizes --- \n",
    "# samples_by_window_size will have structure: {78: {char: []}, 36: {char: []}}\n",
    "samples_by_window_size = {}\n",
    "for duration in WINDOW_DURATIONS:\n",
    "    window_size = round(down_sampling_frequency * (duration / 1000))\n",
    "    samples_by_window_size[window_size] = {char: [] for char in characters}\n",
    "    print(f\"Initialized samples dictionary for window size {window_size} (duration {duration}ms)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded characters from ../../data/characters.txt: ABCDEFGHIJKLMNOPQRSTUVWXYZ123456789_\n",
      "Initialized samples dictionary for window size 78 (duration 650ms)\n",
      "Initialized samples dictionary for window size 36 (duration 300ms)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "f84049b6958260a5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Loop Through Contributors"
   ]
  },
  {
   "cell_type": "code",
   "id": "b1b9c226b30c2c21",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-10T12:38:52.607120930Z",
     "start_time": "2026-01-10T12:38:45.610296422Z"
    }
   },
   "source": [
    "for contributor_selected in contributors_to_process:\n",
    "    print(f\"\\n{'=' * 20} Processing Contributor: {contributor_selected} {'=' * 20}\")\n",
    "    contributor_data_file_path = f\"../../data/contributor_{contributor_selected}.mat\"\n",
    "\n",
    "    # Check if data file exists for the current contributor\n",
    "    if not os.path.exists(contributor_data_file_path):\n",
    "        print(\n",
    "            f\"Warning: data file not found for contributor {contributor_selected} at {contributor_data_file_path}. Skipping this contributor.\")\n",
    "        continue  # Skip to the next contributor\n",
    "\n",
    "    # --- Load Data ---\n",
    "    print(f\"Loading data from: {contributor_data_file_path}\")\n",
    "    try:\n",
    "        data = loadmat(contributor_data_file_path)\n",
    "        signals = data[\"Signal\"]  # Shape: (Trials, Samples, Channels)\n",
    "        flashing = data[\"Flashing\"]\n",
    "        stimulus = data[\"StimulusType\"]\n",
    "        word_raw = data[\"TargetChar\"]  # Expected: String of target chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for contributor {contributor_selected}: {e}. Skipping this contributor.\")\n",
    "        continue\n",
    "        \n",
    "    # --- Data Consistency Checks & Target Character Extraction ---\n",
    "    num_signal_trials = signals.shape[0]\n",
    "    print(f\"Number of trials based on Signal array: {num_signal_trials}\")\n",
    "\n",
    "    target_char_string = None\n",
    "    if isinstance(word_raw, np.ndarray):\n",
    "        if word_raw.size == 1:\n",
    "            target_char_string = str(word_raw.item()).strip()\n",
    "        else:\n",
    "            print(f\"Warning: Unexpected shape for TargetChar: {word_raw.shape}. Trying to flatten.\")\n",
    "            try:\n",
    "                target_char_string = \"\".join(map(str, word_raw.flatten()))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing TargetChar array: {e}\")\n",
    "    elif isinstance(word_raw, str):\n",
    "        target_char_string = word_raw.strip()\n",
    "    else:\n",
    "        print(f\"Error: Unexpected type for TargetChar: {type(word_raw)}\")\n",
    "\n",
    "    if target_char_string is None:\n",
    "        print(\"Error: Could not extract target character string. Skipping this contributor.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Extracted Target Character String (length {len(target_char_string)}): {target_char_string[:50]}...\")\n",
    "\n",
    "\n",
    "    if len(target_char_string) != num_signal_trials:\n",
    "        print(\n",
    "            f\"Error: Length of TargetChar string ({len(target_char_string)}) does not match number of trials in Signal ({num_signal_trials}). Please check data integrity.\")\n",
    "        print(\"Warning: Proceeding with minimum of the two lengths for processing this contributor.\")\n",
    "        trials_to_process = min(len(target_char_string), num_signal_trials)\n",
    "    else:\n",
    "        trials_to_process = num_signal_trials\n",
    "        print(\"TargetChar string length matches number of signal trials.\")\n",
    "\n",
    "    print(f\"\\n Data Info (Initial):\")\n",
    "    print_data(signals, target_char_string, contributor_selected, initial_sampling_frequency)\n",
    "\n",
    "    # --- Butterworth Filter ---\n",
    "    print(\"Applying Butterworth filter...\")\n",
    "    sampling_frequency = initial_sampling_frequency\n",
    "    b, a = signal.butter(4, [0.1 / sampling_frequency, 20 / sampling_frequency], \"bandpass\")\n",
    "    for trial in range(num_signal_trials):\n",
    "        try:\n",
    "            signals[trial, :, :] = signal.filtfilt(b, a, signals[trial, :, :], axis=0)\n",
    "        except IndexError:\n",
    "            print(f\"Error: IndexError during filtering trial {trial}. Check signal dimensions.\")\n",
    "            continue\n",
    "    print(\"Filtering complete.\")\n",
    "\n",
    "    # --- Down-sampling ---\n",
    "    print(f\"Downsampling signals from {initial_sampling_frequency}Hz to {down_sampling_frequency}Hz...\")\n",
    "    SCALE_FACTOR = round(initial_sampling_frequency / down_sampling_frequency)\n",
    "    sampling_frequency = down_sampling_frequency\n",
    "\n",
    "    print(f\"# Samples of EEG signals before downsampling: {signals.shape[1]}\")\n",
    "    try:\n",
    "        signals = signals[:, ::SCALE_FACTOR, :]\n",
    "        flashing = flashing[:, ::SCALE_FACTOR]\n",
    "        stimulus = stimulus[:, ::SCALE_FACTOR]\n",
    "    except IndexError as e:\n",
    "        print(f\"Error during downsampling: {e}. Check array dimensions after filtering.\")\n",
    "        continue  # Skip feature extraction for this contributor if downsampling fails\n",
    "    print(f\"# Samples of EEG signals after downsampling: {signals.shape[1]}\")\n",
    "    print(\"Downsampling complete.\")\n",
    "\n",
    "    # --- Feature Extraction & Grouping for EACH WINDOW SIZE ---\n",
    "    SAMPLES_PER_TRIAL = signals.shape[1]\n",
    "    \n",
    "    for duration in WINDOW_DURATIONS:\n",
    "        WINDOW_SAMPLES = round(sampling_frequency * (duration / 1000))\n",
    "        print(f\"\\n--- Extracting features with window size {WINDOW_SAMPLES} (duration {duration}ms) ---\")\n",
    "        \n",
    "        contributor_samples_collected = 0\n",
    "        for trial in range(trials_to_process):  # 1 - 85 \n",
    "            target_char = target_char_string[trial]\n",
    "\n",
    "            if target_char not in samples_by_window_size[WINDOW_SAMPLES]:\n",
    "                print(\n",
    "                    f\"Warning: Target character '{target_char}' from trial {trial} not found in characters.txt. Skipping this trial.\")\n",
    "                continue\n",
    "                \n",
    "            if trial >= flashing.shape[0] or trial >= stimulus.shape[0]:\n",
    "                print(\n",
    "                    f\"Warning: Trial index {trial} out of bounds for flashing/stimulus arrays. Stopping processing for this contributor.\")\n",
    "                break\n",
    "\n",
    "            for sample_idx in range(SAMPLES_PER_TRIAL):  # 0 - 3394\n",
    "                is_flash_start = False\n",
    "                \n",
    "                try:\n",
    "                    if sample_idx >= flashing.shape[1]: break\n",
    "                    if sample_idx == 0 and flashing[trial, sample_idx] == 1:\n",
    "                        is_flash_start = True\n",
    "                    elif sample_idx > 0:\n",
    "                        if sample_idx - 1 >= flashing.shape[1]: break\n",
    "                        if flashing[trial, sample_idx - 1] == 0 and flashing[trial, sample_idx] == 1:\n",
    "                            is_flash_start = True\n",
    "                except IndexError:\n",
    "                    print(f\"Warning: IndexError accessing flashing at trial {trial}, sample {sample_idx}. Skipping sample.\")\n",
    "                    continue\n",
    "                    \n",
    "                if stimulus[trial,sample_idx]==0:\n",
    "                    continue\n",
    "\n",
    "                if is_flash_start:\n",
    "                    lower_sample = sample_idx\n",
    "                    upper_sample = sample_idx + WINDOW_SAMPLES\n",
    "                    if upper_sample > SAMPLES_PER_TRIAL: continue\n",
    "\n",
    "                    try:\n",
    "                        if upper_sample > signals.shape[1]: continue\n",
    "                        window = signals[trial, lower_sample:upper_sample, :]\n",
    "                    except IndexError:\n",
    "                        print(\n",
    "                            f\"Warning: IndexError extracting window at trial {trial}, samples {lower_sample}:{upper_sample}. Skipping window.\")\n",
    "                        continue\n",
    "\n",
    "                    if window.shape[0] != WINDOW_SAMPLES: continue\n",
    "\n",
    "                    try:\n",
    "                        if window.size == 0 or np.all(np.std(window, axis=0) == 0):\n",
    "                            normalized_window = window\n",
    "                        else:\n",
    "                            normalized_window = scale(window, axis=0)\n",
    "                    except ValueError as e:\n",
    "                        print(\n",
    "                            f\"Warning: ValueError during scaling window at trial {trial}, sample {sample_idx}: {e}. Skipping window.\")\n",
    "                        continue\n",
    "\n",
    "                    # Append to the dictionary for this window size\n",
    "                    samples_by_window_size[WINDOW_SAMPLES][target_char].append(normalized_window)\n",
    "                    contributor_samples_collected += 1\n",
    "\n",
    "        print(\n",
    "            f\"Feature extraction complete for window size {WINDOW_SAMPLES}. Added {contributor_samples_collected} samples.\")\n",
    "            \n",
    "# --- End of Contributor Loop ---\n",
    "print(f\"\\n{'=' * 20} Finished Processing All Contributors {'=' * 20}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Processing Contributor: II ====================\n",
      "Loading data from: ../../data/contributor_II.mat\n",
      "Number of trials based on Signal array: 85\n",
      "Extracted Target Character String (length 85): VGREAAH8TVRHBYN_UGCOLO4EUERDOOHCIFOMDNU6LQCPKEIREK...\n",
      "TargetChar string length matches number of signal trials.\n",
      "\n",
      " Data Info (Initial):\n",
      "Contributor     Sampling Freq. (Hz)  Recording (min)      Chars      Spelled Word                  \n",
      "==============================================================================================================\n",
      "II              240.00               46.01                85         VGREAAH8TVRHBYN_UGCOLO4EUERDOO\n",
      "                                                                     HCIFOMDNU6LQCPKEIREKOYRQIDJXPB\n",
      "                                                                     KOJDWZEUEWWFOEBHXTQTTZUMO     \n",
      "\n",
      "Applying Butterworth filter...\n",
      "Filtering complete.\n",
      "Downsampling signals from 240Hz to 120Hz...\n",
      "# Samples of EEG signals before downsampling: 7794\n",
      "# Samples of EEG signals after downsampling: 3897\n",
      "Downsampling complete.\n",
      "\n",
      "--- Extracting features with window size 78 (duration 650ms) ---\n",
      "Feature extraction complete for window size 78. Added 2550 samples.\n",
      "\n",
      "--- Extracting features with window size 36 (duration 300ms) ---\n",
      "Feature extraction complete for window size 36. Added 2550 samples.\n",
      "\n",
      "==================== Finished Processing All Contributors ====================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "57bc85c26e0286fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Verification"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2a80453dcce8992",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-10T12:38:52.827393823Z",
     "start_time": "2026-01-10T12:38:52.743702674Z"
    }
   },
   "source": [
    "# Verification for both window sizes\n",
    "for window_size, samples in samples_by_window_size.items():\n",
    "    print(f\"\\n{'=' * 20} Window Size: {window_size} {'=' * 20}\")\n",
    "    print(\"Total number of windows per character:\")\n",
    "    total_win_collected = 0\n",
    "    for char, char_samples in samples.items():\n",
    "        count = len(char_samples)\n",
    "        if count > 0:\n",
    "            print(f\"Character '{char}': {count} windows\")\n",
    "        total_win_collected += count\n",
    "    print(f\"\\nTotal windows collected: {total_win_collected}\")\n",
    "    \n",
    "    # Print First Sample for Character 'A'\n",
    "    char_to_print = 'A'\n",
    "    if char_to_print in samples and samples[char_to_print]:\n",
    "        sample_data = samples[char_to_print][0]\n",
    "        print(f\"\\nFirst sample for '{char_to_print}' - Shape: {sample_data.shape}\")\n",
    "    else:\n",
    "        print(f\"No samples found for character '{char_to_print}'\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Window Size: 78 ====================\n",
      "Total number of windows per character:\n",
      "Character 'A': 60 windows\n",
      "Character 'B': 90 windows\n",
      "Character 'C': 90 windows\n",
      "Character 'D': 120 windows\n",
      "Character 'E': 240 windows\n",
      "Character 'F': 60 windows\n",
      "Character 'G': 60 windows\n",
      "Character 'H': 120 windows\n",
      "Character 'I': 90 windows\n",
      "Character 'J': 60 windows\n",
      "Character 'K': 90 windows\n",
      "Character 'L': 60 windows\n",
      "Character 'M': 60 windows\n",
      "Character 'N': 60 windows\n",
      "Character 'O': 270 windows\n",
      "Character 'P': 60 windows\n",
      "Character 'Q': 90 windows\n",
      "Character 'R': 150 windows\n",
      "Character 'T': 120 windows\n",
      "Character 'U': 150 windows\n",
      "Character 'V': 60 windows\n",
      "Character 'W': 90 windows\n",
      "Character 'X': 60 windows\n",
      "Character 'Y': 60 windows\n",
      "Character 'Z': 60 windows\n",
      "Character '4': 30 windows\n",
      "Character '6': 30 windows\n",
      "Character '8': 30 windows\n",
      "Character '_': 30 windows\n",
      "\n",
      "Total windows collected: 2550\n",
      "\n",
      "First sample for 'A' - Shape: (78, 64)\n",
      "\n",
      "==================== Window Size: 36 ====================\n",
      "Total number of windows per character:\n",
      "Character 'A': 60 windows\n",
      "Character 'B': 90 windows\n",
      "Character 'C': 90 windows\n",
      "Character 'D': 120 windows\n",
      "Character 'E': 240 windows\n",
      "Character 'F': 60 windows\n",
      "Character 'G': 60 windows\n",
      "Character 'H': 120 windows\n",
      "Character 'I': 90 windows\n",
      "Character 'J': 60 windows\n",
      "Character 'K': 90 windows\n",
      "Character 'L': 60 windows\n",
      "Character 'M': 60 windows\n",
      "Character 'N': 60 windows\n",
      "Character 'O': 270 windows\n",
      "Character 'P': 60 windows\n",
      "Character 'Q': 90 windows\n",
      "Character 'R': 150 windows\n",
      "Character 'T': 120 windows\n",
      "Character 'U': 150 windows\n",
      "Character 'V': 60 windows\n",
      "Character 'W': 90 windows\n",
      "Character 'X': 60 windows\n",
      "Character 'Y': 60 windows\n",
      "Character 'Z': 60 windows\n",
      "Character '4': 30 windows\n",
      "Character '6': 30 windows\n",
      "Character '8': 30 windows\n",
      "Character '_': 30 windows\n",
      "\n",
      "Total windows collected: 2550\n",
      "\n",
      "First sample for 'A' - Shape: (36, 64)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "8880bd7955777d34",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  Group samples according to three strategies"
   ]
  },
  {
   "cell_type": "code",
   "id": "846981811b9ef29f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-10T12:38:53.206253810Z",
     "start_time": "2026-01-10T12:38:52.835612506Z"
    }
   },
   "source": [
    "import pickle\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Get contributor name from the configuration\n",
    "contributor_name = \"_\".join(contributors_to_process)  # Join all contributors if multiple\n",
    "\n",
    "# Grouping strategies for both window sizes\n",
    "repetition_strategies = {\n",
    "    5: {\"name\": \"5_rep\", \"samples_per_chunk\": 10},\n",
    "    10: {\"name\": \"10_rep\", \"samples_per_chunk\": 20},\n",
    "    15: {\"name\": \"15_rep\", \"samples_per_chunk\": 30}\n",
    "}\n",
    "\n",
    "CHUNK_SIZE = 30  # Divide total windows into chunks of 30\n",
    "\n",
    "print(\"\\nStarting sample grouping process...\")\n",
    "print(f\"Contributor(s): {contributor_name}\")\n",
    "\n",
    "# Process each window size\n",
    "for window_size, samples in samples_by_window_size.items():\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Processing Window Size: {window_size}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    \n",
    "    # Process each repetition strategy\n",
    "    for num_reps, strategy_info in repetition_strategies.items():\n",
    "        strategy_name = strategy_info[\"name\"]\n",
    "        samples_per_chunk = strategy_info[\"samples_per_chunk\"]\n",
    "        \n",
    "        print(f\"\\n--- Strategy: {num_reps} repetitions ({samples_per_chunk} samples per chunk) ---\")\n",
    "        \n",
    "        sample_groups = {}  # Dictionary for this strategy\n",
    "        \n",
    "        # Process each character\n",
    "        for char, char_samples_list in samples.items():\n",
    "            num_samples = len(char_samples_list)\n",
    "            \n",
    "            if num_samples == 0:\n",
    "                sample_groups[char] = []\n",
    "                continue\n",
    "            \n",
    "            # Divide samples into chunks of 30\n",
    "            num_chunks = math.ceil(num_samples / CHUNK_SIZE)\n",
    "            char_grouped_samples = []\n",
    "            \n",
    "            for chunk_idx in range(num_chunks):\n",
    "                start_idx = chunk_idx * CHUNK_SIZE\n",
    "                end_idx = min(start_idx + CHUNK_SIZE, num_samples)\n",
    "                chunk = char_samples_list[start_idx:end_idx]\n",
    "                \n",
    "                # Take the first N samples from this chunk (where N = samples_per_chunk)\n",
    "                samples_to_take = min(samples_per_chunk, len(chunk))\n",
    "                for sample in chunk[:samples_to_take]:\n",
    "                    char_grouped_samples.append(sample)\n",
    "            \n",
    "            sample_groups[char] = char_grouped_samples\n",
    "            \n",
    "            if num_samples > 0:\n",
    "                print(f\"  Character '{char}': {num_samples} windows -> {len(char_grouped_samples)} images\")\n",
    "        \n",
    "        # Save to pickle file with dynamic contributor name\n",
    "        output_filepath = f\"../../data/characters_eeg_{contributor_name}_window{window_size}_{strategy_name}.pkl\"\n",
    "        print(f\"\\nSaving to: {output_filepath}\")\n",
    "        \n",
    "        try:\n",
    "            with open(output_filepath, \"wb\") as f:\n",
    "                pickle.dump(sample_groups, f)\n",
    "            print(f\"Successfully saved!\")\n",
    "            \n",
    "            # Verification\n",
    "            total_images = sum(len(samples) for samples in sample_groups.values())\n",
    "            print(f\"Total images in this file: {total_images}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Finished creating all 6 pickle files!\")\n",
    "print(\"=\" * 50)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting sample grouping process...\n",
      "Contributor(s): II\n",
      "\n",
      "==================================================\n",
      "Processing Window Size: 78\n",
      "==================================================\n",
      "\n",
      "--- Strategy: 5 repetitions (10 samples per chunk) ---\n",
      "  Character 'A': 60 windows -> 20 images\n",
      "  Character 'B': 90 windows -> 30 images\n",
      "  Character 'C': 90 windows -> 30 images\n",
      "  Character 'D': 120 windows -> 40 images\n",
      "  Character 'E': 240 windows -> 80 images\n",
      "  Character 'F': 60 windows -> 20 images\n",
      "  Character 'G': 60 windows -> 20 images\n",
      "  Character 'H': 120 windows -> 40 images\n",
      "  Character 'I': 90 windows -> 30 images\n",
      "  Character 'J': 60 windows -> 20 images\n",
      "  Character 'K': 90 windows -> 30 images\n",
      "  Character 'L': 60 windows -> 20 images\n",
      "  Character 'M': 60 windows -> 20 images\n",
      "  Character 'N': 60 windows -> 20 images\n",
      "  Character 'O': 270 windows -> 90 images\n",
      "  Character 'P': 60 windows -> 20 images\n",
      "  Character 'Q': 90 windows -> 30 images\n",
      "  Character 'R': 150 windows -> 50 images\n",
      "  Character 'T': 120 windows -> 40 images\n",
      "  Character 'U': 150 windows -> 50 images\n",
      "  Character 'V': 60 windows -> 20 images\n",
      "  Character 'W': 90 windows -> 30 images\n",
      "  Character 'X': 60 windows -> 20 images\n",
      "  Character 'Y': 60 windows -> 20 images\n",
      "  Character 'Z': 60 windows -> 20 images\n",
      "  Character '4': 30 windows -> 10 images\n",
      "  Character '6': 30 windows -> 10 images\n",
      "  Character '8': 30 windows -> 10 images\n",
      "  Character '_': 30 windows -> 10 images\n",
      "\n",
      "Saving to: ../../data/characters_eeg_II_window78_5_rep.pkl\n",
      "Successfully saved!\n",
      "Total images in this file: 850\n",
      "\n",
      "--- Strategy: 10 repetitions (20 samples per chunk) ---\n",
      "  Character 'A': 60 windows -> 40 images\n",
      "  Character 'B': 90 windows -> 60 images\n",
      "  Character 'C': 90 windows -> 60 images\n",
      "  Character 'D': 120 windows -> 80 images\n",
      "  Character 'E': 240 windows -> 160 images\n",
      "  Character 'F': 60 windows -> 40 images\n",
      "  Character 'G': 60 windows -> 40 images\n",
      "  Character 'H': 120 windows -> 80 images\n",
      "  Character 'I': 90 windows -> 60 images\n",
      "  Character 'J': 60 windows -> 40 images\n",
      "  Character 'K': 90 windows -> 60 images\n",
      "  Character 'L': 60 windows -> 40 images\n",
      "  Character 'M': 60 windows -> 40 images\n",
      "  Character 'N': 60 windows -> 40 images\n",
      "  Character 'O': 270 windows -> 180 images\n",
      "  Character 'P': 60 windows -> 40 images\n",
      "  Character 'Q': 90 windows -> 60 images\n",
      "  Character 'R': 150 windows -> 100 images\n",
      "  Character 'T': 120 windows -> 80 images\n",
      "  Character 'U': 150 windows -> 100 images\n",
      "  Character 'V': 60 windows -> 40 images\n",
      "  Character 'W': 90 windows -> 60 images\n",
      "  Character 'X': 60 windows -> 40 images\n",
      "  Character 'Y': 60 windows -> 40 images\n",
      "  Character 'Z': 60 windows -> 40 images\n",
      "  Character '4': 30 windows -> 20 images\n",
      "  Character '6': 30 windows -> 20 images\n",
      "  Character '8': 30 windows -> 20 images\n",
      "  Character '_': 30 windows -> 20 images\n",
      "\n",
      "Saving to: ../../data/characters_eeg_II_window78_10_rep.pkl\n",
      "Successfully saved!\n",
      "Total images in this file: 1700\n",
      "\n",
      "--- Strategy: 15 repetitions (30 samples per chunk) ---\n",
      "  Character 'A': 60 windows -> 60 images\n",
      "  Character 'B': 90 windows -> 90 images\n",
      "  Character 'C': 90 windows -> 90 images\n",
      "  Character 'D': 120 windows -> 120 images\n",
      "  Character 'E': 240 windows -> 240 images\n",
      "  Character 'F': 60 windows -> 60 images\n",
      "  Character 'G': 60 windows -> 60 images\n",
      "  Character 'H': 120 windows -> 120 images\n",
      "  Character 'I': 90 windows -> 90 images\n",
      "  Character 'J': 60 windows -> 60 images\n",
      "  Character 'K': 90 windows -> 90 images\n",
      "  Character 'L': 60 windows -> 60 images\n",
      "  Character 'M': 60 windows -> 60 images\n",
      "  Character 'N': 60 windows -> 60 images\n",
      "  Character 'O': 270 windows -> 270 images\n",
      "  Character 'P': 60 windows -> 60 images\n",
      "  Character 'Q': 90 windows -> 90 images\n",
      "  Character 'R': 150 windows -> 150 images\n",
      "  Character 'T': 120 windows -> 120 images\n",
      "  Character 'U': 150 windows -> 150 images\n",
      "  Character 'V': 60 windows -> 60 images\n",
      "  Character 'W': 90 windows -> 90 images\n",
      "  Character 'X': 60 windows -> 60 images\n",
      "  Character 'Y': 60 windows -> 60 images\n",
      "  Character 'Z': 60 windows -> 60 images\n",
      "  Character '4': 30 windows -> 30 images\n",
      "  Character '6': 30 windows -> 30 images\n",
      "  Character '8': 30 windows -> 30 images\n",
      "  Character '_': 30 windows -> 30 images\n",
      "\n",
      "Saving to: ../../data/characters_eeg_II_window78_15_rep.pkl\n",
      "Successfully saved!\n",
      "Total images in this file: 2550\n",
      "\n",
      "==================================================\n",
      "Processing Window Size: 36\n",
      "==================================================\n",
      "\n",
      "--- Strategy: 5 repetitions (10 samples per chunk) ---\n",
      "  Character 'A': 60 windows -> 20 images\n",
      "  Character 'B': 90 windows -> 30 images\n",
      "  Character 'C': 90 windows -> 30 images\n",
      "  Character 'D': 120 windows -> 40 images\n",
      "  Character 'E': 240 windows -> 80 images\n",
      "  Character 'F': 60 windows -> 20 images\n",
      "  Character 'G': 60 windows -> 20 images\n",
      "  Character 'H': 120 windows -> 40 images\n",
      "  Character 'I': 90 windows -> 30 images\n",
      "  Character 'J': 60 windows -> 20 images\n",
      "  Character 'K': 90 windows -> 30 images\n",
      "  Character 'L': 60 windows -> 20 images\n",
      "  Character 'M': 60 windows -> 20 images\n",
      "  Character 'N': 60 windows -> 20 images\n",
      "  Character 'O': 270 windows -> 90 images\n",
      "  Character 'P': 60 windows -> 20 images\n",
      "  Character 'Q': 90 windows -> 30 images\n",
      "  Character 'R': 150 windows -> 50 images\n",
      "  Character 'T': 120 windows -> 40 images\n",
      "  Character 'U': 150 windows -> 50 images\n",
      "  Character 'V': 60 windows -> 20 images\n",
      "  Character 'W': 90 windows -> 30 images\n",
      "  Character 'X': 60 windows -> 20 images\n",
      "  Character 'Y': 60 windows -> 20 images\n",
      "  Character 'Z': 60 windows -> 20 images\n",
      "  Character '4': 30 windows -> 10 images\n",
      "  Character '6': 30 windows -> 10 images\n",
      "  Character '8': 30 windows -> 10 images\n",
      "  Character '_': 30 windows -> 10 images\n",
      "\n",
      "Saving to: ../../data/characters_eeg_II_window36_5_rep.pkl\n",
      "Successfully saved!\n",
      "Total images in this file: 850\n",
      "\n",
      "--- Strategy: 10 repetitions (20 samples per chunk) ---\n",
      "  Character 'A': 60 windows -> 40 images\n",
      "  Character 'B': 90 windows -> 60 images\n",
      "  Character 'C': 90 windows -> 60 images\n",
      "  Character 'D': 120 windows -> 80 images\n",
      "  Character 'E': 240 windows -> 160 images\n",
      "  Character 'F': 60 windows -> 40 images\n",
      "  Character 'G': 60 windows -> 40 images\n",
      "  Character 'H': 120 windows -> 80 images\n",
      "  Character 'I': 90 windows -> 60 images\n",
      "  Character 'J': 60 windows -> 40 images\n",
      "  Character 'K': 90 windows -> 60 images\n",
      "  Character 'L': 60 windows -> 40 images\n",
      "  Character 'M': 60 windows -> 40 images\n",
      "  Character 'N': 60 windows -> 40 images\n",
      "  Character 'O': 270 windows -> 180 images\n",
      "  Character 'P': 60 windows -> 40 images\n",
      "  Character 'Q': 90 windows -> 60 images\n",
      "  Character 'R': 150 windows -> 100 images\n",
      "  Character 'T': 120 windows -> 80 images\n",
      "  Character 'U': 150 windows -> 100 images\n",
      "  Character 'V': 60 windows -> 40 images\n",
      "  Character 'W': 90 windows -> 60 images\n",
      "  Character 'X': 60 windows -> 40 images\n",
      "  Character 'Y': 60 windows -> 40 images\n",
      "  Character 'Z': 60 windows -> 40 images\n",
      "  Character '4': 30 windows -> 20 images\n",
      "  Character '6': 30 windows -> 20 images\n",
      "  Character '8': 30 windows -> 20 images\n",
      "  Character '_': 30 windows -> 20 images\n",
      "\n",
      "Saving to: ../../data/characters_eeg_II_window36_10_rep.pkl\n",
      "Successfully saved!\n",
      "Total images in this file: 1700\n",
      "\n",
      "--- Strategy: 15 repetitions (30 samples per chunk) ---\n",
      "  Character 'A': 60 windows -> 60 images\n",
      "  Character 'B': 90 windows -> 90 images\n",
      "  Character 'C': 90 windows -> 90 images\n",
      "  Character 'D': 120 windows -> 120 images\n",
      "  Character 'E': 240 windows -> 240 images\n",
      "  Character 'F': 60 windows -> 60 images\n",
      "  Character 'G': 60 windows -> 60 images\n",
      "  Character 'H': 120 windows -> 120 images\n",
      "  Character 'I': 90 windows -> 90 images\n",
      "  Character 'J': 60 windows -> 60 images\n",
      "  Character 'K': 90 windows -> 90 images\n",
      "  Character 'L': 60 windows -> 60 images\n",
      "  Character 'M': 60 windows -> 60 images\n",
      "  Character 'N': 60 windows -> 60 images\n",
      "  Character 'O': 270 windows -> 270 images\n",
      "  Character 'P': 60 windows -> 60 images\n",
      "  Character 'Q': 90 windows -> 90 images\n",
      "  Character 'R': 150 windows -> 150 images\n",
      "  Character 'T': 120 windows -> 120 images\n",
      "  Character 'U': 150 windows -> 150 images\n",
      "  Character 'V': 60 windows -> 60 images\n",
      "  Character 'W': 90 windows -> 90 images\n",
      "  Character 'X': 60 windows -> 60 images\n",
      "  Character 'Y': 60 windows -> 60 images\n",
      "  Character 'Z': 60 windows -> 60 images\n",
      "  Character '4': 30 windows -> 30 images\n",
      "  Character '6': 30 windows -> 30 images\n",
      "  Character '8': 30 windows -> 30 images\n",
      "  Character '_': 30 windows -> 30 images\n",
      "\n",
      "Saving to: ../../data/characters_eeg_II_window36_15_rep.pkl\n",
      "Successfully saved!\n",
      "Total images in this file: 2550\n",
      "\n",
      "==================================================\n",
      "Finished creating all 6 pickle files!\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
