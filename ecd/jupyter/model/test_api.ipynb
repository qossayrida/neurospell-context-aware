{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T09:34:47.213955500Z",
     "start_time": "2025-06-15T09:34:47.177987900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 37 characters from ../../data/characters.txt (including added space)\n",
      "Vocabulary size: 37\n",
      "Characters in vocabulary: ABCDEFGHIJKLMNOPQRSTUVWXYZ123456789_ \n",
      "Reading sentences from: ../../data/sentences.txt\n",
      "Read 400 sentences.\n",
      "Model loaded from ../../model/api/char_predictor.pth.\n"
     ]
    }
   ],
   "source": [
    "from bundle.DataCraft import * \n",
    "from bundle.ApiCraft  import * \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load characters from file\n",
    "all_chars = load_characters()\n",
    "char2idx = {ch: idx for idx, ch in enumerate(all_chars)}\n",
    "idx2char = {idx: ch for ch, idx in char2idx.items()}\n",
    "vocab_size = len(all_chars)\n",
    "\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "print(\"Characters in vocabulary:\", all_chars)\n",
    "\n",
    "\n",
    "def predict_next_chars(model, sentence, top_k=None):\n",
    " \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Convert to indices, skipping unknown characters\n",
    "        input_seq = [char2idx[ch] for ch in sentence if ch in char2idx]\n",
    "        if not input_seq:\n",
    "            print(\"Warning: Input sentence contains no known characters. Using empty sequence.\")\n",
    "            # Return uniform distribution if no valid input\n",
    "            result = {ch: 1.0/vocab_size for ch in all_chars}\n",
    "            return result\n",
    "\n",
    "        input_seq = torch.tensor(input_seq).unsqueeze(0)\n",
    "        output = model(input_seq)\n",
    "        probs = F.softmax(output, dim=-1).squeeze(0)\n",
    "        \n",
    "        # If top_k is specified, get only top k predictions\n",
    "        if top_k is not None:\n",
    "            top_k = min(top_k, vocab_size)  # Ensure top_k doesn't exceed vocab size\n",
    "            top_probs, top_indices = torch.topk(probs, top_k)\n",
    "            \n",
    "            result = {}\n",
    "            for prob, idx in zip(top_probs, top_indices):\n",
    "                result[idx2char[idx.item()]] = round(prob.item(), 4)\n",
    "        else:\n",
    "            # Return all probabilities\n",
    "            result = {}\n",
    "            for idx, prob in enumerate(probs):\n",
    "                result[idx2char[idx]] = round(prob.item(), 4)\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# Read Sentences\n",
    "sentences_filepath = \"../../data/sentences.txt\"             # Input: Sentences file\n",
    "\n",
    "sentences = []\n",
    "print(f\"Reading sentences from: {sentences_filepath}\")\n",
    "try:\n",
    "    with open(sentences_filepath, \"r\") as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()] # Read non-empty lines\n",
    "    print(f\"Read {len(sentences)} sentences.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Sentences file not found at {sentences_filepath}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading sentences file: {e}\")\n",
    "    exit()\n",
    "\n",
    "if not sentences:\n",
    "    print(\"No sentences found in the file. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "model = load_nlp_model(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model accuracy on next character prediction...\n",
      "Accuracy on next-character prediction: 76.67%\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Accuracy Evaluation\n",
    "# ===========================\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "print(\"Evaluating model accuracy on next character prediction...\")\n",
    "\n",
    "for sentence in sentences:\n",
    "\n",
    "    for i in range(1, len(sentence)):\n",
    "        \n",
    "        input_seq = sentence[:i]        # Input so far\n",
    "        target_char = sentence[i]       # The correct next character\n",
    "\n",
    "        top_k = 5  # Change this to top-1, top-5, etc.\n",
    "\n",
    "        # Get model predictions\n",
    "        prediction = predict_next_chars(model, input_seq, top_k=top_k)\n",
    "        \n",
    "        # Skip empty predictions\n",
    "        if not prediction:\n",
    "            continue\n",
    "        \n",
    "        # Sort predictions by probability\n",
    "        sorted_preds = sorted(prediction.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Check if target character is in top-k predictions\n",
    "        predicted_chars = [char for char, prob in sorted_preds[:top_k]]\n",
    "        if target_char in predicted_chars:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "\n",
    "accuracy = (correct / total) * 100 if total > 0 else 0.0\n",
    "print(f\"Accuracy on next-character prediction: {accuracy:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T09:34:51.614636400Z",
     "start_time": "2025-06-15T09:34:47.206955400Z"
    }
   },
   "id": "b33c6120f089804b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
