{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eede0c9b",
   "metadata": {},
   "source": [
    "# Comprehensive EEG Model Training\n",
    "Train 36 models with different configurations:\n",
    "- Type 1: EEG only (78 or 36 samples)\n",
    "- Type 2: EEG + Probability data (78+36 or 36+36)\n",
    "- Window sizes: 78, 36\n",
    "- Sensor configurations: 64, 16, 8 channels\n",
    "- Repetitions: 5, 10, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98762355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Add the parent directory to the path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "from bundle.DataCraft import *\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Sensor configurations\n",
    "SENSOR_CONFIGS = {\n",
    "    64: list(range(64)),  # All channels\n",
    "    16: [9, 11, 13, 32, 34, 36, 49, 51, 53, 56, 57, 59, 60, 61],\n",
    "    8: [10, 33, 48, 50, 52, 55, 59, 61]\n",
    "}\n",
    "\n",
    "# Training configurations\n",
    "CONTRIBUTORS = [\"I\", \"II\"]\n",
    "WINDOW_SIZES = [78, 36]\n",
    "REPETITIONS = [5, 10, 15]\n",
    "SENSOR_COUNTS = [64, 16, 8]\n",
    "DATA_TYPES = [\"eeg_only\", \"eeg_with_prob\"]\n",
    "\n",
    "NUM_CLASSES = 36\n",
    "PROB_WINDOW_SIZE = 36\n",
    "\n",
    "print(f\"Total models to train: {len(DATA_TYPES) * len(WINDOW_SIZES) * len(SENSOR_COUNTS) * len(REPETITIONS)} per contributor\")\n",
    "print(f\"Total across all contributors: {len(CONTRIBUTORS) * len(DATA_TYPES) * len(WINDOW_SIZES) * len(SENSOR_COUNTS) * len(REPETITIONS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8046fd",
   "metadata": {},
   "source": [
    "# Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGOnlyDataset(Dataset):\n",
    "    \"\"\"Dataset for EEG data only (without probability matrix)\"\"\"\n",
    "    def __init__(self, data, label_encoder, selected_channels, window_size):\n",
    "        self.data = data\n",
    "        self.label_encoder = label_encoder\n",
    "        self.selected_channels = selected_channels\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get EEG data only (first window_size rows)\n",
    "        eeg_data = self.data[idx][\"eeg_with_prob\"][:self.window_size, :]  # Shape: (window_size, 64)\n",
    "        eeg_data = eeg_data[:, self.selected_channels]  # Shape: (window_size, n_channels)\n",
    "        \n",
    "        # Add time dimension for 3D CNN: (1, 1, window_size, n_channels)\n",
    "        eeg_data = torch.tensor(eeg_data, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        label = self.label_encoder.transform([self.data[idx][\"character\"]])[0]\n",
    "        return eeg_data, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "class EEGWithProbDataset(Dataset):\n",
    "    \"\"\"Dataset for EEG data with probability matrix\"\"\"\n",
    "    def __init__(self, data, label_encoder, selected_channels, window_size):\n",
    "        self.data = data\n",
    "        self.label_encoder = label_encoder\n",
    "        self.selected_channels = selected_channels\n",
    "        self.window_size = window_size\n",
    "        self.total_size = window_size + PROB_WINDOW_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get full data (EEG + probability matrix)\n",
    "        full_data = self.data[idx][\"eeg_with_prob\"]  # Shape: (window_size+36, 64)\n",
    "        full_data = full_data[:, self.selected_channels]  # Shape: (window_size+36, n_channels)\n",
    "        \n",
    "        # Add time dimension for 3D CNN: (1, 1, window_size+36, n_channels)\n",
    "        full_data = torch.tensor(full_data, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        label = self.label_encoder.transform([self.data[idx][\"character\"]])[0]\n",
    "        return full_data, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb232e34",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a82f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, max(channels // reduction, 1), bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(channels // reduction, 1), channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class AdaptiveEEGCNN(nn.Module):\n",
    "    def __init__(self, input_time_steps, input_channels, num_classes=NUM_CLASSES):\n",
    "        super(AdaptiveEEGCNN, self).__init__()\n",
    "        \n",
    "        # Adaptive architecture based on input size\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=(3, 3, 1), padding=(1, 1, 0))\n",
    "        self.bn1 = nn.BatchNorm3d(16)\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=(3, 3, 1), padding=(1, 1, 0))\n",
    "        self.bn2 = nn.BatchNorm3d(32)\n",
    "        self.se1 = SEBlock(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=(3, 3, 1), padding=(1, 1, 0))\n",
    "        self.bn3 = nn.BatchNorm3d(64)\n",
    "        self.se2 = SEBlock(64)\n",
    "        \n",
    "        # Adaptive pooling and fully connected layers\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool3d((4, 4, 1))\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: (B, 1, 1, time_steps, channels)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.se1(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.se2(x)\n",
    "        \n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d5982",
   "metadata": {},
   "source": [
    "# Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76020117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=100, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train model and return training history\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    convergence_epoch = None\n",
    "    convergence_threshold = 0.001\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if convergence_epoch is None and epoch > 10:\n",
    "            if len(train_losses) >= 5:\n",
    "                recent_losses = train_losses[-5:]\n",
    "                loss_variance = np.var(recent_losses)\n",
    "                if loss_variance < convergence_threshold:\n",
    "                    convergence_epoch = epoch + 1\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'final_val_accuracy': val_accuracies[-1],\n",
    "        'convergence_epoch': convergence_epoch,\n",
    "        'training_time': total_time\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    precision = precision_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "\n",
    "def save_results(config, results, model_path, results_path, convergence_path):\n",
    "    \"\"\"\n",
    "    Save model results to files\n",
    "    \"\"\"\n",
    "    # Save convergence data to CSV\n",
    "    convergence_data = {\n",
    "        'epoch': list(range(1, len(results['train_losses']) + 1)),\n",
    "        'train_loss': results['train_losses'],\n",
    "        'val_accuracy': results['val_accuracies']\n",
    "    }\n",
    "    pd.DataFrame(convergence_data).to_csv(convergence_path, index=False)\n",
    "    \n",
    "    # Save detailed results to text file\n",
    "    with open(results_path, 'w') as f:\n",
    "        f.write(f\"Model Configuration:\\n\")\n",
    "        f.write(f\"Contributor: {config['contributor']}\\n\")\n",
    "        f.write(f\"Data Type: {config['data_type']}\\n\")\n",
    "        f.write(f\"Window Size: {config['window_size']}\\n\")\n",
    "        f.write(f\"Sensor Count: {config['sensor_count']}\\n\")\n",
    "        f.write(f\"Repetitions: {config['repetitions']}\\n\")\n",
    "        f.write(f\"\\nResults:\\n\")\n",
    "        f.write(f\"Final Validation Accuracy: {results['final_val_accuracy']:.4f}\\n\")\n",
    "        f.write(f\"Training Time: {results['training_time']:.2f} seconds\\n\")\n",
    "        f.write(f\"Convergence Epoch: {results['convergence_epoch']}\\n\")\n",
    "        f.write(f\"\\nModel Path: {model_path}\\n\")\n",
    "        f.write(f\"Convergence Data: {convergence_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe742e7",
   "metadata": {},
   "source": [
    "# Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_config(contributor, window_size, repetitions, data_type):\n",
    "    \"\"\"\n",
    "    Load training and validation data for specific configuration\n",
    "    \"\"\"\n",
    "    # Construct file paths\n",
    "    if data_type == \"eeg_only\":\n",
    "        # For EEG only, we load the combined data but use only EEG part\n",
    "        train_path = f\"../../data/sentences_eeg_train_{contributor}_window{window_size}_{repetitions}_rep.pkl\"\n",
    "        val_path = f\"../../data/sentences_eeg_val_{contributor}_window{window_size}_{repetitions}_rep.pkl\"\n",
    "    else:  # eeg_with_prob\n",
    "        # For EEG with prob, use the full combined data\n",
    "        train_path = f\"../../data/sentences_eeg_train_{contributor}_window{window_size}_{repetitions}_rep.pkl\"\n",
    "        val_path = f\"../../data/sentences_eeg_val_{contributor}_window{window_size}_{repetitions}_rep.pkl\"\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        with open(train_path, 'rb') as f:\n",
    "            train_data = pickle.load(f)\n",
    "        with open(val_path, 'rb') as f:\n",
    "            val_data = pickle.load(f)\n",
    "        \n",
    "        print(f\"Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "        return train_data, val_data\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Data file not found: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4951b",
   "metadata": {},
   "source": [
    "# Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = \"../../model/comprehensive_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Summary results\n",
    "all_results = []\n",
    "model_counter = 0\n",
    "total_models = len(CONTRIBUTORS) * len(DATA_TYPES) * len(WINDOW_SIZES) * len(SENSOR_COUNTS) * len(REPETITIONS)\n",
    "\n",
    "print(f\"Starting training of {total_models} models...\\n\")\n",
    "\n",
    "for contributor in CONTRIBUTORS:\n",
    "    for data_type in DATA_TYPES:\n",
    "        for window_size in WINDOW_SIZES:\n",
    "            for sensor_count in SENSOR_COUNTS:\n",
    "                for repetitions in REPETITIONS:\n",
    "                    model_counter += 1\n",
    "                    \n",
    "                    config = {\n",
    "                        'contributor': contributor,\n",
    "                        'data_type': data_type,\n",
    "                        'window_size': window_size,\n",
    "                        'sensor_count': sensor_count,\n",
    "                        'repetitions': repetitions\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"\\n{'='*80}\")\n",
    "                    print(f\"Model {model_counter}/{total_models}\")\n",
    "                    print(f\"Config: {config}\")\n",
    "                    print(f\"{'='*80}\")\n",
    "                    \n",
    "                    # Load data\n",
    "                    train_data, val_data = load_data_for_config(\n",
    "                        contributor, window_size, repetitions, data_type\n",
    "                    )\n",
    "                    \n",
    "                    if train_data is None or val_data is None:\n",
    "                        print(f\"Skipping model {model_counter} due to data loading error\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Create label encoder\n",
    "                    all_labels = [item[\"character\"] for item in train_data] + [item[\"character\"] for item in val_data]\n",
    "                    label_encoder = LabelEncoder()\n",
    "                    label_encoder.fit(all_labels)\n",
    "                    \n",
    "                    # Get selected channels\n",
    "                    selected_channels = SENSOR_CONFIGS[sensor_count]\n",
    "                    \n",
    "                    # Create datasets\n",
    "                    if data_type == \"eeg_only\":\n",
    "                        train_dataset = EEGOnlyDataset(train_data, label_encoder, selected_channels, window_size)\n",
    "                        val_dataset = EEGOnlyDataset(val_data, label_encoder, selected_channels, window_size)\n",
    "                        input_time_steps = window_size\n",
    "                    else:  # eeg_with_prob\n",
    "                        train_dataset = EEGWithProbDataset(train_data, label_encoder, selected_channels, window_size)\n",
    "                        val_dataset = EEGWithProbDataset(val_data, label_encoder, selected_channels, window_size)\n",
    "                        input_time_steps = window_size + PROB_WINDOW_SIZE\n",
    "                    \n",
    "                    # Create data loaders\n",
    "                    batch_size = min(32, len(train_dataset) // 4)  # Adaptive batch size\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    \n",
    "                    # Create model\n",
    "                    model = AdaptiveEEGCNN(\n",
    "                        input_time_steps=input_time_steps,\n",
    "                        input_channels=sensor_count,\n",
    "                        num_classes=NUM_CLASSES\n",
    "                    ).to(DEVICE)\n",
    "                    \n",
    "                    # File paths\n",
    "                    model_name = f\"model_{contributor}_{data_type}_w{window_size}_s{sensor_count}_r{repetitions}\"\n",
    "                    model_path = os.path.join(results_dir, f\"{model_name}.pth\")\n",
    "                    results_path = os.path.join(results_dir, f\"{model_name}_results.txt\")\n",
    "                    convergence_path = os.path.join(results_dir, f\"{model_name}_convergence.csv\")\n",
    "                    \n",
    "                    # Train model\n",
    "                    print(f\"Training {model_name}...\")\n",
    "                    results = train_model(model, train_loader, val_loader, epochs=100)\n",
    "                    \n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    \n",
    "                    # Save results\n",
    "                    save_results(config, results, model_path, results_path, convergence_path)\n",
    "                    \n",
    "                    # Add to summary\n",
    "                    summary_result = config.copy()\n",
    "                    summary_result.update({\n",
    "                        'final_accuracy': results['final_val_accuracy'],\n",
    "                        'convergence_epoch': results['convergence_epoch'],\n",
    "                        'training_time': results['training_time'],\n",
    "                        'model_path': model_path\n",
    "                    })\n",
    "                    all_results.append(summary_result)\n",
    "                    \n",
    "                    print(f\"Completed {model_name} | Accuracy: {results['final_val_accuracy']:.4f}\")\n",
    "                    \n",
    "                    # Clean up GPU memory\n",
    "                    del model, train_loader, val_loader, train_dataset, val_dataset\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58430471",
   "metadata": {},
   "source": [
    "# Save Summary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary CSV\n",
    "summary_df = pd.DataFrame(all_results)\n",
    "summary_path = os.path.join(results_dir, \"training_summary.csv\")\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n",
    "print(f\"\\nTotal models trained: {len(all_results)}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== SUMMARY STATISTICS ===\")\n",
    "for data_type in DATA_TYPES:\n",
    "    for window_size in WINDOW_SIZES:\n",
    "        for sensor_count in SENSOR_COUNTS:\n",
    "            subset = summary_df[\n",
    "                (summary_df['data_type'] == data_type) & \n",
    "                (summary_df['window_size'] == window_size) & \n",
    "                (summary_df['sensor_count'] == sensor_count)\n",
    "            ]\n",
    "            if not subset.empty:\n",
    "                avg_acc = subset['final_accuracy'].mean()\n",
    "                print(f\"{data_type} | Window {window_size} | {sensor_count} sensors: {avg_acc:.4f} avg accuracy\")\n",
    "\n",
    "print(f\"\\nAll results saved to: {results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
