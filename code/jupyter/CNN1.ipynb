{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CNN1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svppQZlrES-H",
    "colab_type": "text"
   },
   "source": [
    "# CNN1 SETTINGS\n",
    "\n",
    "SUBJECT'S DATA SELECTION:                                                                                                  \n",
    "- **A**: Signal samples: 7794, EEG channels: 64, Testset letters: 100                                                           \n",
    "- **B**: Signal samples: 7794, EEG channels: 64, Testset letters: 100 "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9nw7AE3rLWlk",
    "colab_type": "code",
    "outputId": "7803c2e1-5c85-4905-b669-015a77b7721f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576424435959,
     "user_tz": -60,
     "elapsed": 37713,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:09.953624200Z",
     "start_time": "2024-12-29T23:06:07.610277700Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np     \n",
    "import random           \n",
    "from scipy.io import loadmat\n",
    "from scipy import signal\n",
    "import warnings\n",
    "import string\n",
    "import os\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Install mne library for topoplot\n",
    "!pip install mne\n",
    "import mne\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "####################### SETTINGS ########################\n",
    "# Set this variable with the desidered subject's letter #\n",
    "SUBJECT_SELECTED = \"II\"                                 #\n",
    "#########################################################\n",
    "\n",
    "subject_names = [\"I\", \"II\"]\n",
    "\n",
    "\n",
    "# Google drive data paths\n",
    "MODEL_LOCATIONS_FILE_PATH = '../model/CNN1/' + SUBJECT_SELECTED\n",
    "SUBJECT_TRAIN_FILE_PATH = '../data/Contributor_' + SUBJECT_SELECTED + '_Train.mat'\n",
    "SUBJECT_TEST_FILE_PATH = '../data/Contributor_' + SUBJECT_SELECTED + '_Test.mat'\n",
    "CHANNEL_LOCATIONS_FILE_PATH = '../data/channels.csv'\n",
    "CHANNEL_COORD = '../data/coordinates.csv'\n",
    "\n",
    "# Channel selection\n",
    "CHANNELS = [i for i in range(64)]"
   ],
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: decorator in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (3.1.5)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (3.10.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (2.0.2)\n",
      "Requirement already satisfied: packaging in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (24.2)\n",
      "Requirement already satisfied: pooch>=1.5 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (1.14.1)\n",
      "Requirement already satisfied: tqdm in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from matplotlib>=3.6->mne) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from matplotlib>=3.6->mne) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from matplotlib>=3.6->mne) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from pooch>=1.5->mne) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: colorama in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.12.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\university\\year 4 semester 1\\encs5200\\brainwaveresearch\\code\\venv\\lib\\site-packages)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVrJuHCMFCSl",
    "colab_type": "text"
   },
   "source": [
    "# Training set processing\n",
    "\n",
    "1.   Application of bandpass filter **(0.1-20Hz)**;\n",
    "2.   Down-sampling signals from 240Hz to 120Hz;\n",
    "3.   Obtain windows of 650ms at the start of every flashing (175ms)\n",
    "4.   Normalization of samples in each window: **Zi = (Xi - mu) / sigma**;\n",
    "5.   Reshape each window to be a 3D tensor with dimensions: **(N_SAMPLES, 78, 64)**;\n",
    "6.   Obtain **(noP300 / P300)** class ratio to balance out dataset during training;"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "78aU0w6-Lp0y",
    "colab_type": "code",
    "outputId": "d1b22ce0-1858-4007-85a8-e169316ae6ef",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576424445216,
     "user_tz": -60,
     "elapsed": 3901,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:10.089781400Z",
     "start_time": "2024-12-29T23:06:09.954628Z"
    }
   },
   "source": [
    "if not os.path.exists(SUBJECT_TRAIN_FILE_PATH):\n",
    "    print(\"Missing file: {}\".format(SUBJECT_TRAIN_FILE_PATH))\n",
    "else:\n",
    "    # Load the required data\n",
    "    data = loadmat(SUBJECT_TRAIN_FILE_PATH)\n",
    "    # Get the variables of interest from the loaded dictionary\n",
    "    signals = data['Signal']\n",
    "    flashing = data['Flashing']\n",
    "    stimulus = data['StimulusType']\n",
    "    word = data['TargetChar']\n",
    "    \n",
    "    SAMPLING_FREQUENCY = 240\n",
    "    # From the dataset description we know that there are 15 repetitions\n",
    "    REPETITIONS = 15\n",
    "    # Compute the duration of the recording in minutes\n",
    "    RECORDING_DURATION = (len(signals))*(len(signals[0]))/(SAMPLING_FREQUENCY*60)\n",
    "    # Compute number of trials\n",
    "    TRIALS = len(word[0])\n",
    "    # Set flag to True to balance the training set\n",
    "    BALANCE_DATASET = False\n",
    "\n",
    "    print(\"**********************************\")\n",
    "    print(\"       TRAIN SET INFORMATION      \")\n",
    "    print(\"**********************************\")\n",
    "    print(\"Sampling Frequency: %d Hz [%.2f ms]\" % (SAMPLING_FREQUENCY, (1000/SAMPLING_FREQUENCY)))\n",
    "    print(\"Session duration:   %.2f min\" % RECORDING_DURATION)\n",
    "    print(\"Number of letters:  %d\" % TRIALS)\n",
    "    print(\"Spelled word:       %s\" % ''.join(word))"
   ],
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "       TRAIN SET INFORMATION      \n",
      "**********************************\n",
      "Sampling Frequency: 240 Hz [4.17 ms]\n",
      "Session duration:   46.01 min\n",
      "Number of letters:  85\n",
      "Spelled word:       VGREAAH8TVRHBYN_UGCOLO4EUERDOOHCIFOMDNU6LQCPKEIREKOYRQIDJXPBKOJDWZEUEWWFOEBHXTQTTZUMO\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IXuVC7puKcLt",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:13.463630Z",
     "start_time": "2024-12-29T23:06:10.093293800Z"
    }
   },
   "source": [
    "# Application of butterworth filter\n",
    "b, a = signal.butter(4, [0.1/SAMPLING_FREQUENCY, 20/SAMPLING_FREQUENCY], 'bandpass')\n",
    "for trial in range(TRIALS):\n",
    "    signals[trial, :, :] = signal.filtfilt(b, a, signals[trial, :, :], axis=0)"
   ],
   "execution_count": 165,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jS1FuKDuixnF",
    "colab_type": "code",
    "outputId": "f4fc2a89-1f8c-48a9-f060-727e77b8aa94",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576424450421,
     "user_tz": -60,
     "elapsed": 2945,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:13.477468600Z",
     "start_time": "2024-12-29T23:06:13.467168800Z"
    }
   },
   "source": [
    "# Down-sampling of the signals from 240Hz to 120Hz\n",
    "DOWNSAMPLING_FREQUENCY = 120\n",
    "SCALE_FACTOR = round(SAMPLING_FREQUENCY / DOWNSAMPLING_FREQUENCY)\n",
    "SAMPLING_FREQUENCY = DOWNSAMPLING_FREQUENCY\n",
    "\n",
    "print(\"# Samples of EEG signals before downsampling: {}\".format(len(signals[0])))\n",
    "\n",
    "signals = signals[:, 0:-1:SCALE_FACTOR, :]\n",
    "flashing = flashing[:, 0:-1:SCALE_FACTOR]\n",
    "stimulus = stimulus[:, 0:-1:SCALE_FACTOR]\n",
    "\n",
    "print(\"# Samples of EEG signals after downsampling: {}\".format(len(signals[0])))"
   ],
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Samples of EEG signals before downsampling: 7794\n",
      "# Samples of EEG signals after downsampling: 3897\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bGaRKwu9MIvP",
    "colab_type": "code",
    "outputId": "12e9ec3d-fac7-46c8-d21c-64e302f8399e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576424452130,
     "user_tz": -60,
     "elapsed": 2050,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:14.072314100Z",
     "start_time": "2024-12-29T23:06:13.539286900Z"
    }
   },
   "source": [
    "# Number of EEG channels\n",
    "N_CHANNELS = len(CHANNELS)\n",
    "# Window duration after each flashing [ms]\n",
    "WINDOW_DURATION = 650\n",
    "# Number of samples of each window\n",
    "WINDOW_SAMPLES = round(SAMPLING_FREQUENCY * (WINDOW_DURATION / 1000))\n",
    "# Number of samples for each character in trials\n",
    "SAMPLES_PER_TRIAL = len(signals[0])\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "\n",
    "for trial in range(TRIALS):\n",
    "    for sample in (range(SAMPLES_PER_TRIAL)):\n",
    "        if (sample == 0) or (flashing[trial, sample-1] == 0 and flashing[trial, sample] == 1):\n",
    "            lower_sample = sample\n",
    "            upper_sample = sample + WINDOW_SAMPLES\n",
    "            window = signals[trial, lower_sample:upper_sample, :]                \n",
    "            # Features extraction\n",
    "            train_features.append(window)\n",
    "            # Labels extraction\n",
    "            if stimulus[trial, sample] == 1:\n",
    "                count_positive += 1\n",
    "                train_labels.append(1) # Class P300\n",
    "            else:\n",
    "                count_negative += 1\n",
    "                train_labels.append(0) # Class no-P300\n",
    "\n",
    "# Get negative-positive classes ratio\n",
    "train_ratio = count_negative/count_positive\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# 3D Tensor shape (SAMPLES, 64, 78)\n",
    "dim_train = train_features.shape\n",
    "print(\"Features tensor shape: {}\".format(dim_train))"
   ],
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features tensor shape: (15300, 78, 64)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kKMlV1Mqapew",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:20.290154500Z",
     "start_time": "2024-12-29T23:06:14.071340100Z"
    }
   },
   "source": [
    "# Data normalization Zi = (Xi - mu) / sigma\n",
    "for pattern in range(len(train_features)):\n",
    "    train_features[pattern] = scale(train_features[pattern], axis=0)"
   ],
   "execution_count": 168,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTVrfKzJH2aE",
    "colab_type": "text"
   },
   "source": [
    "# Testing set processing\n",
    "\n",
    "1.   Application of bandpass filter **(0.1-20Hz)**;\n",
    "2.   Down-sampling signas from 240Hz to 120Hz;\n",
    "3.   Obtain windows of 650ms at the start of every flashing (175ms)\n",
    "4.   Normalization of samples in each window: **Zi = (Xi - mu) / sigma**;\n",
    "5.   Reshape each window to be a 3D tensor with dimensions: **(N_SAMPLES, 78, 64)**;\n",
    "6.   Calculate weights vector to balance samples importance and obtain correct accuracy estimation;"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nm-bZZsKTliz",
    "colab_type": "code",
    "outputId": "06dcbd08-67c2-4826-de3d-99dc9b2a24d6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576424466616,
     "user_tz": -60,
     "elapsed": 11382,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:21.268869700Z",
     "start_time": "2024-12-29T23:06:20.288114Z"
    }
   },
   "source": [
    "# Test data loading\n",
    "if not os.path.exists(SUBJECT_TEST_FILE_PATH):\n",
    "    print(\"Missing file: {}\", SUBJECT_TEST_FILE_PATH)\n",
    "else:\n",
    "    # Load the required data\n",
    "    data_test = loadmat(SUBJECT_TEST_FILE_PATH)\n",
    "    # Get the variables of interest from the loaded dictionary\n",
    "    signals_test = data_test['Signal']\n",
    "    flashing_test = data_test['Flashing']\n",
    "    word_test =  data_test['TargetChar']\n",
    "    stimulus_code_test = data_test['StimulusCode']\n",
    "\n",
    "    SAMPLING_FREQUENCY = 240\n",
    "    # From the dataset description we know that there are 15 repetitions\n",
    "    REPETITIONS = 15\n",
    "    # Compute the duration of the recording in minutes\n",
    "    RECORDING_DURATION_TEST = (len(signals_test))*(len(signals_test[0]))/(SAMPLING_FREQUENCY*60)\n",
    "    # Compute number of trials\n",
    "    TRIALS_TEST = len(word_test[0])\n",
    "    # Number of samples for each character in trials\n",
    "    SAMPLES_PER_TRIAL_TEST = len(signals_test[0])\n",
    "    \n",
    "    print(\"**********************************\")\n",
    "    print(\"        TEST SET INFORMATION      \")\n",
    "    print(\"**********************************\")\n",
    "    print(\"Sampling Frequency: %d Hz [%.2f ms]\" % (SAMPLING_FREQUENCY, (1000/SAMPLING_FREQUENCY)))\n",
    "    print(\"Session duration:   %.2f min\" % RECORDING_DURATION_TEST)\n",
    "    print(\"Number of letters:  %d\" % TRIALS_TEST)\n",
    "    print(\"Spelled word:       %s\" % ''.join(word_test))"
   ],
   "execution_count": 169,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "        TEST SET INFORMATION      \n",
      "**********************************\n",
      "Sampling Frequency: 240 Hz [4.17 ms]\n",
      "Session duration:   54.12 min\n",
      "Number of letters:  100\n",
      "Spelled word:       MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SvCresQJm25A",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:21.823128200Z",
     "start_time": "2024-12-29T23:06:21.273835700Z"
    }
   },
   "source": [
    "# Create characters matrix\n",
    "char_matrix = [[0 for j in range(6)] for i in range(6)]\n",
    "s = string.ascii_uppercase + '1' + '2' + '3' + '4' + '5' + '6' + '7' + '8' + '9' + '_'\n",
    "\n",
    "# Append cols and rows in a list\n",
    "list_matrix = []\n",
    "for i in range(6):\n",
    "    col = [s[j] for j in range(i, 36, 6)]\n",
    "    list_matrix.append(col)\n",
    "for i in range(6):\n",
    "    row = [s[j] for j in range(i * 6, i * 6 + 6)]\n",
    "    list_matrix.append(row)\n",
    "\n",
    "# Create StimulusType array for the test set (missing from the given database)\n",
    "stimulus_test = [[0 for j in range(SAMPLES_PER_TRIAL_TEST)] for i in range(TRIALS_TEST)]\n",
    "stimulus_test = np.array(stimulus_test)\n",
    "\n",
    "for trial in range(TRIALS_TEST):\n",
    "    counter=0\n",
    "    for sample in range(SAMPLES_PER_TRIAL_TEST):\n",
    "        index = int(stimulus_code_test[trial, sample]) - 1\n",
    "        if not index == -1:\n",
    "            if word_test[0][trial] in list_matrix[index]:\n",
    "                stimulus_test[trial, sample] = 1\n",
    "            else:\n",
    "                stimulus_test[trial, sample] = 0"
   ],
   "execution_count": 170,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UNy5oI8ooMAw",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:25.772454Z",
     "start_time": "2024-12-29T23:06:21.824636400Z"
    }
   },
   "source": [
    "# Application of butterworth filter\n",
    "b, a = signal.butter(4, [0.1/SAMPLING_FREQUENCY, 20/SAMPLING_FREQUENCY], 'bandpass')\n",
    "for trial in range(TRIALS_TEST):\n",
    "    signals_test[trial, :, :] = signal.filtfilt(b, a, signals_test[trial, :, :], axis=0)"
   ],
   "execution_count": 171,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8CpKeth5qOjr",
    "colab_type": "code",
    "outputId": "d68e24c4-ce36-4404-855d-ae1352a5c898",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576424470296,
     "user_tz": -60,
     "elapsed": 8124,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:25.787545700Z",
     "start_time": "2024-12-29T23:06:25.775964100Z"
    }
   },
   "source": [
    "# Down-sampling of the signals from 240Hz to 120Hz\n",
    "DOWNSAMPLING_FREQUENCY = 120\n",
    "SCALE_FACTOR = round(SAMPLING_FREQUENCY / DOWNSAMPLING_FREQUENCY)\n",
    "SAMPLING_FREQUENCY = DOWNSAMPLING_FREQUENCY\n",
    "\n",
    "print(\"# Samples of EEG signals before downsampling: {}\".format(len(signals_test[0])))\n",
    "\n",
    "signals_test = signals_test[:, 0:-1:SCALE_FACTOR, :]\n",
    "flashing_test = flashing_test[:, 0:-1:SCALE_FACTOR]\n",
    "stimulus_test = stimulus_test[:, 0:-1:SCALE_FACTOR]\n",
    "\n",
    "print(\"# Samples of EEG signals after downsampling: {}\".format(len(signals_test[0])))"
   ],
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Samples of EEG signals before downsampling: 7794\n",
      "# Samples of EEG signals after downsampling: 3897\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "48sta55OVXFy",
    "colab_type": "code",
    "outputId": "fa6aa9d1-0f93-418b-ff8b-5fd0fa9cab82",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576424471791,
     "user_tz": -60,
     "elapsed": 7564,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:26.609964300Z",
     "start_time": "2024-12-29T23:06:25.847991500Z"
    }
   },
   "source": [
    "# Number of EEG channels\n",
    "N_CHANNELS = len(CHANNELS)\n",
    "# Window duration after each flashing [ms]\n",
    "WINDOW_DURATION = 650\n",
    "# Number of samples of each window\n",
    "WINDOW_SAMPLES = round(SAMPLING_FREQUENCY * (WINDOW_DURATION / 1000))\n",
    "# Number of samples for each character in trials\n",
    "SAMPLES_PER_TRIAL_TEST = len(signals[0])\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "windowed_stimulus = []\n",
    "\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "\n",
    "for trial in range(TRIALS_TEST):\n",
    "    for sample in (range(SAMPLES_PER_TRIAL_TEST)):\n",
    "        if (sample == 0) or (flashing_test[trial, sample-1] == 0 and flashing_test[trial, sample] == 1):\n",
    "            lower_sample = sample\n",
    "            upper_sample = sample + WINDOW_SAMPLES\n",
    "            window = signals_test[trial, lower_sample:upper_sample, :]\n",
    "            # Extracting number of row/col in a window\n",
    "            number_stimulus = int(stimulus_code_test[trial, sample])\n",
    "            windowed_stimulus.append(number_stimulus)\n",
    "            # Features extraction\n",
    "            test_features.append(window)\n",
    "            # Labels extraction\n",
    "            if stimulus_test[trial, sample] == 1:\n",
    "                count_positive += 1\n",
    "                test_labels.append(1) # Class P300\n",
    "            else:\n",
    "                count_negative += 1\n",
    "                test_labels.append(0) # Class no-P300\n",
    "\n",
    "# Get test weights to take into account the number of classes \n",
    "test_weights = []\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 1:\n",
    "        test_weights.append(len(test_labels)/count_positive)\n",
    "    else:\n",
    "        test_weights.append(len(test_labels)/count_negative)\n",
    "test_weights = np.array(test_weights)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# 3D tensor (SAMPLES, 64, 78)\n",
    "dim_test = test_features.shape\n",
    "print(\"Features tensor shape: {}\".format(dim_test))"
   ],
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features tensor shape: (18000, 78, 64)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "# Data normalization Zi = (Xi - mu) / sigma\n",
    "for pattern in range(len(test_features)):\n",
    "    test_features[pattern] = scale(test_features[pattern], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:33.772913100Z",
     "start_time": "2024-12-29T23:06:26.606450900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN1 model definition, training and testing\n",
    "\n",
    "1.   Function definiton for randomization of weights and biases;\n",
    "2.   **Scaled_tanh(x)** activation function definition;\n",
    "3.   ANN model definition (2 Conv1D layers, 2 dense layers);\n",
    "4.   Training of the network over weighted dataset;\n",
    "5.   CNN1 performance assessment;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "# Randomizing function for bias and weights of the network\n",
    "def cecotti_normal(shape, dtype = None, partition_info = None):\n",
    "    if len(shape) == 1:\n",
    "        fan_in = shape[0]\n",
    "    elif len(shape) == 2:\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        receptive_field_size = 1\n",
    "        for dim in shape[:-2]:\n",
    "            receptive_field_size *= dim\n",
    "        fan_in = shape[-2] * receptive_field_size\n",
    "    return K.random_normal(shape, mean = 0.0, stddev = (1.0 / fan_in))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:33.786521600Z",
     "start_time": "2024-12-29T23:06:33.775415600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "# Custom tanh activation function\n",
    "def scaled_tanh(z):\n",
    "    return 1.7159 * K.tanh((2.0 / 3.0) * z)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:33.829308700Z",
     "start_time": "2024-12-29T23:06:33.788532300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def CNN1_model(channels=64, filters=10):\n",
    "    model = Sequential([\n",
    "        Conv1D(\n",
    "            filters = filters,\n",
    "            kernel_size = 1,\n",
    "            padding = \"same\",\n",
    "            bias_initializer = cecotti_normal,\n",
    "            kernel_initializer = cecotti_normal,\n",
    "            use_bias = True,\n",
    "            activation = scaled_tanh,\n",
    "            input_shape = (78, channels)\n",
    "        ),\n",
    "        Conv1D(\n",
    "            filters = 50,\n",
    "            kernel_size = 13,\n",
    "            padding = \"valid\",\n",
    "            strides = 11,\n",
    "            bias_initializer = cecotti_normal,\n",
    "            kernel_initializer = cecotti_normal,\n",
    "            use_bias = True,\n",
    "            activation = scaled_tanh,\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(100, activation=\"sigmoid\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:33.830815500Z",
     "start_time": "2024-12-29T23:06:33.808568200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api.backend' has no attribute 'random_normal'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[178], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m SHUFFLE \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;66;03m# set to 1 to shuffle subsets during training\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Model summary\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[43mCNN1_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchannels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msummary()\n",
      "Cell \u001B[1;32mIn[177], line 3\u001B[0m, in \u001B[0;36mCNN1_model\u001B[1;34m(channels, filters)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mCNN1_model\u001B[39m(channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, filters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m----> 3\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mSequential\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mConv1D\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msame\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbias_initializer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcecotti_normal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkernel_initializer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcecotti_normal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m            \u001B[49m\u001B[43muse_bias\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mscaled_tanh\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m78\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mConv1D\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m13\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstrides\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m11\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbias_initializer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcecotti_normal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkernel_initializer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcecotti_normal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m            \u001B[49m\u001B[43muse_bias\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m            \u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mscaled_tanh\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m        \u001B[49m\u001B[43mFlatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m        \u001B[49m\u001B[43mDense\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msigmoid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m        \u001B[49m\u001B[43mDense\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msigmoid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m     model\u001B[38;5;241m.\u001B[39mcompile(optimizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_squared_error\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32mD:\\University\\Year 4 semester 1\\ENCS5200\\BrainWaveResearch\\code\\venv\\lib\\site-packages\\keras\\src\\models\\sequential.py:76\u001B[0m, in \u001B[0;36mSequential.__init__\u001B[1;34m(self, layers, trainable, name)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m layers:\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd(layer, rebuild\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 76\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_rebuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\University\\Year 4 semester 1\\ENCS5200\\BrainWaveResearch\\code\\venv\\lib\\site-packages\\keras\\src\\models\\sequential.py:141\u001B[0m, in \u001B[0;36mSequential._maybe_rebuild\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m0\u001B[39m], InputLayer) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    140\u001B[0m     input_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mbatch_shape\n\u001B[1;32m--> 141\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_shape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;66;03m# We can build the Sequential model if the first layer has the\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001B[39;00m\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;66;03m# model.\u001B[39;00m\n\u001B[0;32m    146\u001B[0m     input_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minput_shape\n",
      "File \u001B[1;32mD:\\University\\Year 4 semester 1\\ENCS5200\\BrainWaveResearch\\code\\venv\\lib\\site-packages\\keras\\src\\layers\\layer.py:226\u001B[0m, in \u001B[0;36mLayer.__new__.<locals>.build_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_open_name_scope():\n\u001B[0;32m    225\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_path \u001B[38;5;241m=\u001B[39m current_path()\n\u001B[1;32m--> 226\u001B[0m     original_build_method(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    227\u001B[0m \u001B[38;5;66;03m# Record build config.\u001B[39;00m\n\u001B[0;32m    228\u001B[0m signature \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(original_build_method)\n",
      "File \u001B[1;32mD:\\University\\Year 4 semester 1\\ENCS5200\\BrainWaveResearch\\code\\venv\\lib\\site-packages\\keras\\src\\models\\sequential.py:187\u001B[0m, in \u001B[0;36mSequential.build\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 187\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m:\n\u001B[0;32m    189\u001B[0m         \u001B[38;5;66;03m# Can happen if shape inference is not implemented.\u001B[39;00m\n\u001B[0;32m    190\u001B[0m         \u001B[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001B[39;00m\n\u001B[0;32m    191\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32mD:\\University\\Year 4 semester 1\\ENCS5200\\BrainWaveResearch\\code\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "Cell \u001B[1;32mIn[175], line 12\u001B[0m, in \u001B[0;36mcecotti_normal\u001B[1;34m(shape, dtype, partition_info)\u001B[0m\n\u001B[0;32m     10\u001B[0m         receptive_field_size \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m dim\n\u001B[0;32m     11\u001B[0m     fan_in \u001B[38;5;241m=\u001B[39m shape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m*\u001B[39m receptive_field_size\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mK\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_normal\u001B[49m(shape, mean \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m, stddev \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m fan_in))\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'keras.api.backend' has no attribute 'random_normal'"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "VALID_SPLIT = 0.05\n",
    "SHUFFLE = 1 # set to 1 to shuffle subsets during training\n",
    "\n",
    "# Model summary\n",
    "CNN1_model(channels=64, filters=10).summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:34.020540700Z",
     "start_time": "2024-12-29T23:06:33.821168200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = CNN1_model(channels=64, filters=10)\n",
    "\n",
    "# Callback to save best model only\n",
    "checkpoint = ModelCheckpoint(filepath=MODEL_LOCATIONS_FILE_PATH + \"/\" + \"model\" + \".h5\", \n",
    "                             monitor='val_loss', \n",
    "                             mode='min',\n",
    "                             save_best_only=True)\n",
    "\n",
    "# Callback to stop when loss on validation set doesn't decrease in 50 epochs\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                              mode = 'min', \n",
    "                              patience = 50, \n",
    "                              restore_best_weights = True)\n",
    "\n",
    "# Callback to keep track of model statistics\n",
    "history = model.fit(x=train_features, \n",
    "                    y=train_labels, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_split=VALID_SPLIT, \n",
    "                    callbacks=[checkpoint, earlystop],\n",
    "                    shuffle=SHUFFLE,\n",
    "                    class_weight={0: 1., 1: train_ratio})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-29T23:06:34.020540700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "# Plots of loss curves during training\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label=\"training loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.title('Loss Curves')\n",
    "\n",
    "# Plots of accuracy curves during training\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label=\"training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "plt.title('Accuracy Curves')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-29T23:06:34.023533600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define model\n",
    "best_model = CNN1_model(channels=64, filters=10)\n",
    "\n",
    "# Load best model weights from h5 file\n",
    "best_model.load_weights(MODEL_LOCATIONS_FILE_PATH + \"/model.keras\")\n",
    "\n",
    "# Compile best model model\n",
    "best_model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-29T23:06:34.026049100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load topoplot coordinates\n",
    "if not os.path.exists(CHANNEL_COORD):\n",
    "    print(\"Missing file: {}\".format(CHANNEL_COORD))\n",
    "else:\n",
    "    xycoord = []\n",
    "    # Read file content\n",
    "    with open(CHANNEL_COORD, \"r\") as f:\n",
    "        file_content = f.read()\n",
    "        # Loop over all rows\n",
    "        for row in file_content.split(\"\\n\"): \n",
    "        # Skip missing rows\n",
    "            if row == '':\n",
    "                continue\n",
    "            xycoord.append(row)\n",
    "\n",
    "# Create a list with x,y coordinates of each electrodes well formatted\n",
    "coord = []\n",
    "for x in xycoord:\n",
    "    coord.append(x.split(','))\n",
    "coord = np.array(coord)\n",
    "\n",
    "# Flip y axis in order to plot in the right way the electrodes positions\n",
    "for i in range(len(coord)):\n",
    "    coord[i][1] = 681 - int(coord[i][1])\n",
    "\n",
    "# Create a list of weights for all filters\n",
    "nf = []\n",
    "for filt in range(10):\n",
    "    nf.append(abs(np.array(best_model.get_weights()[0])[0, :, filt]))\n",
    "nf = np.array(nf, dtype=float)\n",
    "\n",
    "# Plot topoplot of the 10 filters in the first convolutional layer\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2,5,i+1)\n",
    "    ax.set_title(\"Filter #{}\".format(i+1))\n",
    "    mne.viz.plot_topomap(nf[i], coord, cmap='Spectral_r', axes=ax, show=False)\n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-29T23:06:34.027095600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Accuracy over the testing set\n",
    "predictions = best_model.predict(test_features)\n",
    "predictions = np.round(predictions)\n",
    "\n",
    "score = np.array(best_model.evaluate(test_features, test_labels, verbose=0, sample_weight=test_weights))\n",
    "print(\"Model performance on test set:\\t[ Loss: {}\\tAccuracy: {} ]\".format(*score.round(4)))\n",
    "print(\"\\nPredictions: {}\\nSolutions:   {}\".format(list(map(int, predictions))[:50], list(map(int, test_labels))[:50]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:34.031086600Z",
     "start_time": "2024-12-29T23:06:34.029578200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Weighted confusion matrix (noP300: 80%, P300: 20%)\n",
    "data = confusion_matrix(y_true=test_labels, y_pred=predictions, sample_weight=test_weights)\n",
    "\n",
    "# Normalized confusion matrix (values in range 0-1)\n",
    "data_norm = data/np.full(data.shape, len(test_labels))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "df_cm = pd.DataFrame(data_norm, columns=np.unique(test_labels), index = np.unique(test_labels))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (6,5))\n",
    "sns.set(font_scale = 1.4)\n",
    "cm = sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws = {\"size\": 16}, vmin=0, vmax=1)\n",
    "cm.axes.set_title(\"CNN1 confusion matrix\\n\", fontsize=20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-29T23:06:34.043211200Z",
     "start_time": "2024-12-29T23:06:34.032094100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model metrics (sens, spec, ppv, npv)\n",
    "def model_metrics(conf_matrix):\n",
    "    tn, fp, fn, tp = list(data_norm.flatten())\n",
    "    sens = round(tp/(tp+fn),4) # Sensitivity\n",
    "    spec = round(tn/(tn+fp),4) # Specificity\n",
    "    ppv = round(tp/(tp+fp),4) # Positive Predicted Value\n",
    "    npv = round(tn/(tn+fn),4) # Negative Predicted Value\n",
    "    return {\"Sensitivity\":sens, \"Specificity\":spec, \"PPV\":ppv, \"NPV\":npv}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-29T23:06:34.037202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Put model metrics into a table\n",
    "metrics = model_metrics(data_norm)\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(5,1))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Hide graph outlines\n",
    "for item in [fig, ax]:\n",
    "    item.patch.set_visible(False)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Table definition\n",
    "table = ax.table(cellText=[list(metrics.values())], \n",
    "                     colLabels=list(metrics.keys()),\n",
    "                     loc=\"center\",\n",
    "                     cellLoc=\"center\",\n",
    "                     colColours=[\"c\"]*4)\n",
    "table.set_fontsize(16)\n",
    "table.scale(2,2)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-29T23:06:34.038211800Z"
    }
   }
  }
 ]
}
