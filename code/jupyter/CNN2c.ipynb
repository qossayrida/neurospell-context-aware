{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CNN2c.ipynb",
   "provenance": [
    {
     "file_id": "11CKvMWbYn2HYpLAfu2xRhNmw9HDnkG5B",
     "timestamp": 1575826262900
    },
    {
     "file_id": "1nbofAi2dLnhJvkcLl1Xag7I1vx4MPR2s",
     "timestamp": 1575818931262
    },
    {
     "file_id": "1tTQLWB1ve20LC-Cxir5CrLKQ_vDyzeI2",
     "timestamp": 1575815207334
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxCpGqdfnQ2p",
    "colab_type": "text"
   },
   "source": [
    "# CNN2c SETTINGS\n",
    "                                                                                                                          \n",
    "ELECTRODE SUBSET SELECTION:                                                                                                \n",
    "- **F**: Frontal lobe electrodes                                                                                                   \n",
    "- **C**: Central lobe electrodes                                                                                               \n",
    "- **P**: Parietal lobe electrodes                                                                                             \n",
    "- **O**: Occipital lobe electrodes                                                                                            \n",
    "- **LT**: Left temporal lobe electrodes                                                                                       \n",
    "- **RT**: Right temporal lobe electrodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np     \n",
    "import warnings\n",
    "import string\n",
    "import os\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "contributor_selected = \"I\"                                \n",
    "electrode_selected = \"O\"                                \n",
    "electrode_names = [\"F\", \"C\", \"P\", \"O\", \"LT\", \"RT\"]\n",
    "\n",
    "\n",
    "contributor_train_file_path = '../data/Contributor_' + contributor_selected + '_Train.mat'\n",
    "contributor_test_file_path = '../data/Contributor_' + contributor_selected + '_Test.mat'\n",
    "channel_name_file_path = '../data/channels.csv'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Channel selection\n",
    "if electrode_selected == \"F\":\n",
    "    channels = [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
    "elif electrode_selected == \"C\":\n",
    "    channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "elif electrode_selected == \"P\":\n",
    "    channels = [15, 16, 17, 18, 19, 48, 49, 50, 51, 52]\n",
    "elif electrode_selected == \"O\":\n",
    "    channels = [55, 56, 57, 58, 59, 60, 61, 62]\n",
    "elif electrode_selected == \"LT\":\n",
    "    channels = [14, 38, 40, 44, 46, 47]\n",
    "elif electrode_selected == \"RT\":\n",
    "    channels = [20, 39, 41, 45, 53, 54]\n",
    "    \n",
    "\n",
    "img = mpimg.imread(\"../image/brain_view.png\")\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVrJuHCMFCSl",
    "colab_type": "text"
   },
   "source": [
    "# Training set processing\n",
    "\n",
    "1.   Application of bandpass filter **(0.1-20Hz)**;\n",
    "2.   Down-sampling signals from 240Hz to 120Hz;\n",
    "3.   Obtain windows of 650ms at the start of every flashing (175ms)\n",
    "4.   Normalization of samples in each window: **Zi = (Xi - mu) / sigma**;\n",
    "5.   Reshape each window to be a 3D tensor with dimensions: **(N_SAMPLES, 78, N_CHANNELS)**;\n",
    "6.   Obtain **(noP300 / P300)** class ratio to balance out dataset during training;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from scipy import signal\n",
    "from bundle.DataCraft import * \n",
    "\n",
    "data_train = loadmat(contributor_train_file_path)\n",
    "\n",
    "\n",
    "signals_train = data_train['Signal']\n",
    "signals_train = signals_train[:, :, channels]\n",
    "flashing_train = data_train['Flashing']\n",
    "stimulus_train = data_train['StimulusType']\n",
    "word_train = data_train['TargetChar']\n",
    "sampling_frequency = 240\n",
    "repetitions = 15\n",
    "recording_duration_train = (len(signals_train)) * (len(signals_train[0])) / (sampling_frequency * 60)\n",
    "trials_train = len(word_train[0])\n",
    "\n",
    "\n",
    "print(\"Train Data:\")\n",
    "print_data(signals_train, word_train, contributor_selected, sampling_frequency)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Application of butterworth filter\n",
    "b, a = signal.butter(4, [0.1 / sampling_frequency, 20 / sampling_frequency], 'bandpass')\n",
    "for trial in range(trials_train):\n",
    "    signals_train[trial, :, :] = signal.filtfilt(b, a, signals_train[trial, :, :], axis=0)\n",
    "    \n",
    "# Down-sampling of the signals from 240Hz to 120Hz\n",
    "down_sampling_frequency = 120\n",
    "SCALE_FACTOR = round(sampling_frequency / down_sampling_frequency)\n",
    "sampling_frequency = down_sampling_frequency\n",
    "\n",
    "print(\"# Samples of EEG signals before downsampling: {}\".format(len(signals_train[0])))\n",
    "\n",
    "signals_train = signals_train[:, 0:-1:SCALE_FACTOR, :]\n",
    "flashing_train = flashing_train[:, 0:-1:SCALE_FACTOR]\n",
    "stimulus_train = stimulus_train[:, 0:-1:SCALE_FACTOR]\n",
    "\n",
    "print(\"# Samples of EEG signals after downsampling: {}\".format(len(signals_train[0])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of EEG channels\n",
    "N_CHANNELS = 8\n",
    "# Window duration after each flashing [ms]\n",
    "WINDOW_DURATION = 650\n",
    "# Number of samples of each window\n",
    "WINDOW_SAMPLES = round(sampling_frequency * (WINDOW_DURATION / 1000))\n",
    "# Number of samples for each character in trials\n",
    "SAMPLES_PER_TRIAL = len(signals_train[0])\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "\n",
    "for trial in range(trials_train):\n",
    "    for sample in (range(SAMPLES_PER_TRIAL)):\n",
    "        if (sample == 0) or (flashing_train[trial, sample - 1] == 0 and flashing_train[trial, sample] == 1):\n",
    "            lower_sample = sample\n",
    "            upper_sample = sample + WINDOW_SAMPLES\n",
    "            window = signals_train[trial, lower_sample:upper_sample, :]                \n",
    "            # Features extraction\n",
    "            train_features.append(window)\n",
    "            # Labels extraction\n",
    "            if stimulus_train[trial, sample] == 1:\n",
    "                count_positive += 1\n",
    "                train_labels.append(1) # Class P300\n",
    "            else:\n",
    "                count_negative += 1\n",
    "                train_labels.append(0) # Class no-P300\n",
    "\n",
    "# Get negative-positive classes ratio\n",
    "train_ratio = count_negative/count_positive\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# 3D Tensor shape (SAMPLES, 78, 8)\n",
    "dim_train = train_features.shape\n",
    "print(\"Features tensor shape: {}\".format(dim_train))\n",
    "\n",
    "# Data normalization Zi = (Xi - mu) / sigma\n",
    "for pattern in range(len(train_features)):\n",
    "    train_features[pattern] = scale(train_features[pattern], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTVrfKzJH2aE",
    "colab_type": "text"
   },
   "source": [
    "# Testing set processing\n",
    "\n",
    "1.   Application of bandpass filter **(0.1-20Hz)**;\n",
    "2.   Down-sampling signas from 240Hz to 120Hz;\n",
    "3.   Obtain windows of 650ms at the start of every flashing (175ms)\n",
    "4.   Normalization of samples in each window: **Zi = (Xi - mu) / sigma**;\n",
    "5.   Reshape each window to be a 3D tensor with dimensions: **(N_SAMPLES, 78, N_CHANNELS)**;\n",
    "6.   Calculate weights vector to balance samples importance and obtain correct accuracy estimation;"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nm-bZZsKTliz",
    "colab_type": "code",
    "outputId": "377bce66-9fc9-4587-fc47-1921b8ba20f5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426130954,
     "user_tz": -60,
     "elapsed": 39099,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    }
   },
   "source": [
    "data_test = loadmat(contributor_test_file_path)\n",
    "\n",
    "# Get the variables of interest from the loaded dictionary\n",
    "signals_test = data_test['Signal']\n",
    "signals_test = signals_test[:, :, channels]\n",
    "flashing_test = data_test['Flashing']\n",
    "word_test =  data_test['TargetChar']\n",
    "stimulus_code_test = data_test['StimulusCode']\n",
    "sampling_frequency = 240\n",
    "repetitions = 15\n",
    "recording_duration_test = (len(signals_test)) * (len(signals_test[0])) / (sampling_frequency * 60)\n",
    "trials_test = len(word_test[0])\n",
    "samples_per_trial_test = len(signals_test[0])\n",
    "\n",
    "print(\"Test Data:\")\n",
    "print_data(signals_test, word_test, contributor_selected, sampling_frequency)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SvCresQJm25A",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "char_matrix = [[0 for j in range(6)] for i in range(6)]\n",
    "s = string.ascii_uppercase + '1' + '2' + '3' + '4' + '5' + '6' + '7' + '8' + '9' + '_'\n",
    "\n",
    "# Append cols and rows in a list\n",
    "list_matrix = []\n",
    "for i in range(6):\n",
    "    col = [s[j] for j in range(i, 36, 6)]\n",
    "    list_matrix.append(col)\n",
    "for i in range(6):\n",
    "    row = [s[j] for j in range(i * 6, i * 6 + 6)]\n",
    "    list_matrix.append(row)\n",
    "\n",
    "# Create StimulusType array for the test set (missing from the given database)\n",
    "stimulus_test = [[0 for j in range(samples_per_trial_test)] for i in range(trials_test)]\n",
    "stimulus_test = np.array(stimulus_test)\n",
    "\n",
    "for trial in range(trials_test):\n",
    "    counter=0\n",
    "    for sample in range(samples_per_trial_test):\n",
    "        index = int(stimulus_code_test[trial, sample]) - 1\n",
    "        if not index == -1:\n",
    "            if word_test[0][trial] in list_matrix[index]:\n",
    "                stimulus_test[trial, sample] = 1\n",
    "            else:\n",
    "                stimulus_test[trial, sample] = 0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UNy5oI8ooMAw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Application of butterworth filter\n",
    "b, a = signal.butter(4, [0.1 / sampling_frequency, 20 / sampling_frequency], 'bandpass')\n",
    "for trial in range(trials_test):\n",
    "    signals_test[trial, :, :] = signal.filtfilt(b, a, signals_test[trial, :, :], axis=0)\n",
    "    \n",
    "# Down-sampling of the signals from 240Hz to 120Hz\n",
    "down_sampling_frequency = 120\n",
    "SCALE_FACTOR = round(sampling_frequency / down_sampling_frequency)\n",
    "sampling_frequency = down_sampling_frequency\n",
    "\n",
    "print(\"# Samples of EEG signals before downsampling: {}\".format(len(signals_test[0])))\n",
    "\n",
    "signals_test = signals_test[:, 0:-1:SCALE_FACTOR, :]\n",
    "flashing_test = flashing_test[:, 0:-1:SCALE_FACTOR]\n",
    "stimulus_test = stimulus_test[:, 0:-1:SCALE_FACTOR]\n",
    "\n",
    "print(\"# Samples of EEG signals after downsampling: {}\".format(len(signals_test[0])))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "48sta55OVXFy",
    "colab_type": "code",
    "outputId": "918c5a3c-2b95-45a9-e6fe-9a9f24f7fd81",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426133421,
     "user_tz": -60,
     "elapsed": 41506,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    }
   },
   "source": [
    "# Number of EEG channels\n",
    "N_CHANNELS = len(channels)\n",
    "# Window duration after each flashing [ms]\n",
    "WINDOW_DURATION = 650\n",
    "# Number of samples of each window\n",
    "WINDOW_SAMPLES = round(sampling_frequency * (WINDOW_DURATION / 1000))\n",
    "# Number of samples for each character in trials\n",
    "samples_per_trial_test = len(signals_train[0])\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "windowed_stimulus = []\n",
    "\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "\n",
    "for trial in range(trials_test):\n",
    "    for sample in (range(samples_per_trial_test)):\n",
    "        if (sample == 0) or (flashing_test[trial, sample-1] == 0 and flashing_test[trial, sample] == 1):\n",
    "            lower_sample = sample\n",
    "            upper_sample = sample + WINDOW_SAMPLES\n",
    "            window = signals_test[trial, lower_sample:upper_sample, :]\n",
    "            # Extracting number of row/col in a window\n",
    "            number_stimulus = int(stimulus_code_test[trial, sample])\n",
    "            windowed_stimulus.append(number_stimulus)\n",
    "            # Features extraction\n",
    "            test_features.append(window)\n",
    "            # Labels extraction\n",
    "            if stimulus_test[trial, sample] == 1:\n",
    "                count_positive += 1\n",
    "                test_labels.append(1) # Class P300\n",
    "            else:\n",
    "                count_negative += 1\n",
    "                test_labels.append(0) # Class no-P300\n",
    "\n",
    "# Get test weights to take into account the number of classes \n",
    "test_weights = []\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 1:\n",
    "        test_weights.append(len(test_labels)/count_positive)\n",
    "    else:\n",
    "        test_weights.append(len(test_labels)/count_negative)\n",
    "test_weights = np.array(test_weights)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# 3D tensor (SAMPLES, 78, 64)\n",
    "dim_test = test_features.shape\n",
    "print(\"Features tensor shape: {}\".format(dim_test))\n",
    "\n",
    "# Data normalization Zi = (Xi - mu) / sigma\n",
    "for pattern in range(len(test_features)):\n",
    "    test_features[pattern] = scale(test_features[pattern], axis=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VK4MFXTjHoM",
    "colab_type": "text"
   },
   "source": [
    "# CNN2c model definition, training and testing\n",
    "\n",
    "1.   Function definiton for randomization of weights and biases;\n",
    "2.   **Scaled_tanh(x)** activation function definition;\n",
    "3.   ANN model definition (2 Conv1D layers, 2 dense layers);\n",
    "4.   Training of the network over weighted dataset;\n",
    "5.   CNN2c performance assessment;"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eTIc_w_TcOmK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Randomizing function for bias and weights of the network\n",
    "def cecotti_normal(shape, dtype = None, partition_info = None):\n",
    "    if len(shape) == 1:\n",
    "        fan_in = shape[0]\n",
    "    elif len(shape) == 2:\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        receptive_field_size = 1\n",
    "        for dim in shape[:-2]:\n",
    "            receptive_field_size *= dim\n",
    "        fan_in = shape[-2] * receptive_field_size\n",
    "    return K.random_normal(shape, mean = 0.0, stddev = (1.0 / fan_in))\n",
    "\n",
    "# Custom tanh activation function\n",
    "def scaled_tanh(z):\n",
    "    return 1.7159 * K.tanh((2.0 / 3.0) * z)\n",
    "\n",
    "# Build the model\n",
    "def CNN2c_model(channels=N_CHANNELS, filters=10):\n",
    "    model = Sequential([\n",
    "        Conv1D(\n",
    "            filters = filters,\n",
    "            kernel_size = 1,\n",
    "            padding = \"same\",\n",
    "            bias_initializer = cecotti_normal,\n",
    "            kernel_initializer = cecotti_normal,\n",
    "            use_bias = True,\n",
    "            activation = scaled_tanh,\n",
    "            input_shape = (78, channels)\n",
    "        ),\n",
    "        Conv1D(\n",
    "            filters = 50,\n",
    "            kernel_size = 13,\n",
    "            padding = \"valid\",\n",
    "            strides = 11,\n",
    "            bias_initializer = cecotti_normal,\n",
    "            kernel_initializer = cecotti_normal,\n",
    "            use_bias = True,\n",
    "            activation = scaled_tanh,\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(100, activation=\"sigmoid\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 200\n",
    "VALID_SPLIT = 0.05\n",
    "SHUFFLE = 1 # set to 1 to shuffle subsets during training\n",
    "\n",
    "# Model summary\n",
    "model = CNN2c_model(channels=N_CHANNELS, filters=10)\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GEPpgyxyTl-u",
    "colab_type": "code",
    "outputId": "c6f258b6-69d9-4dbf-e8b3-94b4bd07e276",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426172008,
     "user_tz": -60,
     "elapsed": 80012,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# Callback to stop when loss on validation set doesn't decrease in 50 epochs\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                              mode = 'min', \n",
    "                              patience = 50, \n",
    "                              restore_best_weights = True)\n",
    "\n",
    "# Callback to keep track of model statistics\n",
    "history = model.fit(x=train_features, \n",
    "                    y=train_labels, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_split=VALID_SPLIT, \n",
    "                    callbacks=[earlystop],\n",
    "                    shuffle=SHUFFLE,\n",
    "                    class_weight={0: 1., 1: train_ratio})\n",
    "\n",
    "# Find the epoch with the lowest validation loss\n",
    "best_epoch = np.argmin(history.history['val_loss'])\n",
    "print(f\"Best epoch: {best_epoch + 1} with validation loss: {history.history['val_loss'][best_epoch]}\")\n",
    "\n",
    "# Reload the best weights manually\n",
    "best_weights = model.get_weights()\n",
    "model.set_weights(best_weights)\n",
    "\n",
    "# Define a new model to reuse the best configuration\n",
    "best_model = CNN2c_model(channels=8, filters=10)\n",
    "best_model.set_weights(best_weights)\n",
    "\n",
    "# Compile the best model\n",
    "best_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eJHaj2f1VFYZ",
    "colab_type": "code",
    "outputId": "52053b60-0d1b-473d-87a0-7f0f59b490a9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426172929,
     "user_tz": -60,
     "elapsed": 80925,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    }
   },
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "# Plots of loss curves during training\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label=\"training loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plots of accuracy curves during training\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label=\"training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_j_iqu0tYlbS",
    "colab_type": "code",
    "outputId": "86aad8dd-9829-4688-a5bc-806873128295",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426175556,
     "user_tz": -60,
     "elapsed": 83528,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import csv\n",
    "from bundle.DataCraft import electrode_names_to_remove\n",
    "\n",
    "# Read CSV file into a Python list\n",
    "all_electrode_names = []\n",
    "\n",
    "with open(channel_name_file_path, \"r\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        all_electrode_names.extend(row)  # Add each row to the list (handles single-column CSV)\n",
    "\n",
    "\n",
    "# Crate array has names of electrodes from all_electrode_names that have index in channels\n",
    "electrode_names = []\n",
    "for i in range(len(channels)):\n",
    "    electrode_names.append(all_electrode_names[channels[i]])\n",
    "print(electrode_names)\n",
    "\n",
    "\n",
    "\n",
    "# Create array has the original index for electrode_names_to_remove in electrode_names\n",
    "index = []\n",
    "for i in range(len(electrode_names_to_remove)):\n",
    "    if electrode_names_to_remove[i] in electrode_names:\n",
    "        index.append(electrode_names.index(electrode_names_to_remove[i]))\n",
    "print(index)\n",
    "\n",
    "electrode_names = [x for x in electrode_names if x not in electrode_names_to_remove]\n",
    "print(electrode_names)\n",
    "    \n",
    "    \n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "\n",
    "# Create random weights for 10 filters (20 channels)\n",
    "n_channels = len(electrode_names)\n",
    "n_filters = 10\n",
    "\n",
    "# Create a list of weights for all filters\n",
    "nf = []\n",
    "for filt in range(10):\n",
    "    nf.append(abs(np.array(best_model.get_weights()[0])[0, :, filt]))\n",
    "# remove the channels from the weights \n",
    "nf = np.delete(nf, index, axis=1)\n",
    "\n",
    "# Create an Info object with EEG channel names\n",
    "info = mne.create_info(ch_names=electrode_names, sfreq=1000, ch_types=\"eeg\")\n",
    "info.set_montage(montage)\n",
    "\n",
    "# Plot topomap for each filter\n",
    "# Set give me array of background color\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6), facecolor=\"#000000\")  # Set overall background to black\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(n_filters):\n",
    "    ax = axes[i]\n",
    "    mne.viz.plot_topomap(\n",
    "        nf[i], info, axes=ax, cmap=\"Spectral_r\", sphere=1.2, show=False  # Adjust `sphere` to scale brain size\n",
    "    )\n",
    "    ax.set_title(f\"Filter #{i + 1}\", color=\"white\")  # Set title color to white for better visibility\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EzbVkDAwUmfa",
    "colab_type": "code",
    "outputId": "ca5312d0-c969-4c7e-d88d-8f98f889d5ee",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426176170,
     "user_tz": -60,
     "elapsed": 84124,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    }
   },
   "source": [
    "# Accuracy over the testing set\n",
    "predictions = best_model.predict(test_features)\n",
    "predictions = np.round(predictions)\n",
    "\n",
    "score = np.array(best_model.evaluate(test_features, test_labels, verbose=0, sample_weight=test_weights))\n",
    "print(\"Model performance on test set:\\t[ Loss: {}\\tAccuracy: {} ]\".format(*score.round(4)))\n",
    "print(\"\\nPredictions: {}\\nSolutions:   {}\".format(list(map(int, predictions))[:50], list(map(int, test_labels))[:50]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DVKxqyKZpyg8",
    "colab_type": "code",
    "outputId": "976a8aed-3806-4fae-a569-a0af6894ebe0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426176733,
     "user_tz": -60,
     "elapsed": 84674,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    }
   },
   "source": [
    "# Weighted confusion matrix (noP300: 80%, P300: 20%)\n",
    "data_train = confusion_matrix(y_true=test_labels, y_pred=predictions, sample_weight=test_weights)\n",
    "\n",
    "# Normalized confusion matrix (values in range 0-1)\n",
    "data_norm = data_train / np.full(data_train.shape, len(test_labels))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "df_cm = pd.DataFrame(data_norm, columns=np.unique(test_labels), index = np.unique(test_labels))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (6,5))\n",
    "sns.set(font_scale = 1.4)\n",
    "cm = sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws = {\"size\": 16}, vmin=0, vmax=1)\n",
    "cm.axes.set_title(\"CNN2a confusion matrix\\n\", fontsize=20)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JUPsdxe4qrqi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Model metrics (sens, spec, ppv, npv)\n",
    "def model_metrics(conf_matrix):\n",
    "    tn, fp, fn, tp = list(data_norm.flatten())\n",
    "    sens = round(tp/(tp+fn),4) # Sensitivity\n",
    "    spec = round(tn/(tn+fp),4) # Specificity\n",
    "    ppv = round(tp/(tp+fp),4) # Positive Predicted Value\n",
    "    npv = round(tn/(tn+fn),4) # Negative Predicted Value\n",
    "    return {\"Sensitivity\":sens, \"Specificity\":spec, \"PPV\":ppv, \"NPV\":npv}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yo3CmAb2qrt6",
    "colab_type": "code",
    "outputId": "242b6cb7-0602-4515-d8a9-0e37c4ec166d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426176735,
     "user_tz": -60,
     "elapsed": 84647,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    }
   },
   "source": [
    "# Put model metrics into a table\n",
    "metrics = model_metrics(data_norm)\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(5,1))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Hide graph outlines\n",
    "for item in [fig, ax]:\n",
    "    item.patch.set_visible(False)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Table definition\n",
    "table = ax.table(cellText=[list(metrics.values())], \n",
    "                     colLabels=list(metrics.keys()),\n",
    "                     loc=\"center\",\n",
    "                     cellLoc=\"center\",\n",
    "                     colColours=[\"c\"]*4)\n",
    "table.set_fontsize(16)\n",
    "table.scale(2,2)\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
