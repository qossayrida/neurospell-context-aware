{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CNN2c.ipynb",
   "provenance": [
    {
     "file_id": "11CKvMWbYn2HYpLAfu2xRhNmw9HDnkG5B",
     "timestamp": 1575826262900
    },
    {
     "file_id": "1nbofAi2dLnhJvkcLl1Xag7I1vx4MPR2s",
     "timestamp": 1575818931262
    },
    {
     "file_id": "1tTQLWB1ve20LC-Cxir5CrLKQ_vDyzeI2",
     "timestamp": 1575815207334
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxCpGqdfnQ2p",
    "colab_type": "text"
   },
   "source": [
    "# CNN2c SETTINGS\n",
    "\n",
    "SUBJECT'S DATA SELECTION:                                                                                                  \n",
    "- **A**: Signal samples: 7794, EEG channels: 64, Testset letters: 100                                                           \n",
    "- **B**: Signal samples: 7794, EEG channels: 64, Testset letters: 100                                                              \n",
    "                                                                                                                                                   \n",
    "ELECTRODE SUBSET SELECTION:                                                                                                \n",
    "- **F**: Frontal lobe electrodes                                                                                                   \n",
    "- **C**: Central lobe electrodes                                                                                               \n",
    "- **P**: Parietal lobe electrodes                                                                                             \n",
    "- **O**: Occipital lobe electrodes                                                                                            \n",
    "- **LT**: Left temporal lobe electrodes                                                                                       \n",
    "- **RT**: Right temporal lobe electrodes "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9nw7AE3rLWlk",
    "colab_type": "code",
    "outputId": "48f956af-5332-407b-afd0-6370658bf048",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426119179,
     "user_tz": -60,
     "elapsed": 27410,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "ExecuteTime": {
     "end_time": "2024-12-30T19:05:03.138462Z",
     "start_time": "2024-12-30T19:05:02.585306900Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np     \n",
    "import random           \n",
    "from scipy.io import loadmat\n",
    "from scipy import signal\n",
    "from google.colab import drive\n",
    "import warnings\n",
    "import string\n",
    "import os\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Install mne library for topoplot\n",
    "!pip install mne\n",
    "import mne\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "####################### SETTINGS ########################\n",
    "# Set this variable with the desidered subject's letter #\n",
    "SUBJECT_SELECTED = \"B\"                                  #\n",
    "#                                                       #\n",
    "# Set this variable with the desired electrode subset   #\n",
    "ELECTRODE_SELECTED = \"O\"                                #\n",
    "#########################################################\n",
    "\n",
    "subject_names = [\"A\", \"B\"]\n",
    "electrode_names = [\"F\", \"C\", \"P\", \"O\", \"LT\", \"RT\"]\n",
    "\n",
    "# Check for errors in the settings\n",
    "if SUBJECT_SELECTED not in subject_names:\n",
    "    raise ValueError(\"SUBJECT_SELECTED value {} is invalid.\\nPlease enter one of the following parameters {}\".format(SUBJECT_SELECTED, subject_names))\n",
    "elif ELECTRODE_SELECTED not in electrode_names:\n",
    "    raise ValueError(\"ELECTRODE_SELECTED value {} is invalid\\nPlease enter one of the following parameters {}\".format(ELECTRODE_SELECTED, electrodes_names))\n",
    "\n",
    "# Google drive data paths\n",
    "MODEL_LOCATIONS_FILE_PATH = 'drive/My Drive/AY1920_DT_P300_SPELLER_03/Trained_models/CNN2c/' + SUBJECT_SELECTED \n",
    "SUBJECT_TRAIN_FILE_PATH = 'drive/My Drive/AY1920_DT_P300_SPELLER_03/Dataset/Subject_' + SUBJECT_SELECTED + '_Train.mat'\n",
    "SUBJECT_TEST_FILE_PATH = 'drive/My Drive/AY1920_DT_P300_SPELLER_03/Dataset/Subject_' + SUBJECT_SELECTED + '_Test.mat'\n",
    "CHANNEL_LOCATIONS_FILE_PATH = 'drive/My Drive/AY1920_DT_P300_SPELLER_03/Dataset/channels.csv'\n",
    "CHANNEL_COORD = 'drive/My Drive/AY1920_DT_P300_SPELLER_03/Dataset/coordinates.csv'\n",
    "\n",
    "# Channel selection\n",
    "if ELECTRODE_SELECTED == \"F\":\n",
    "    CHANNELS = [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
    "elif ELECTRODE_SELECTED == \"C\":\n",
    "    CHANNELS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "elif ELECTRODE_SELECTED == \"P\":\n",
    "    CHANNELS = [15, 16, 17, 18, 19, 48, 49, 50, 51, 52]\n",
    "elif ELECTRODE_SELECTED == \"O\":\n",
    "    CHANNELS = [55, 56, 57, 58, 59, 60, 61, 62]\n",
    "elif ELECTRODE_SELECTED == \"LT\":\n",
    "    CHANNELS = [14, 38, 40, 44, 46, 47]\n",
    "elif ELECTRODE_SELECTED == \"RT\":\n",
    "    CHANNELS = [20, 39, 41, 45, 53, 54]"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m loadmat\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m signal\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstring\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVrJuHCMFCSl",
    "colab_type": "text"
   },
   "source": [
    "# Training set processing\n",
    "\n",
    "1.   Application of bandpass filter **(0.1-20Hz)**;\n",
    "2.   Down-sampling signals from 240Hz to 120Hz;\n",
    "3.   Obtain windows of 650ms at the start of every flashing (175ms)\n",
    "4.   Normalization of samples in each window: **Zi = (Xi - mu) / sigma**;\n",
    "5.   Reshape each window to be a 3D tensor with dimensions: **(N_SAMPLES, 78, N_CHANNELS)**;\n",
    "6.   Obtain **(noP300 / P300)** class ratio to balance out dataset during training;\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "78aU0w6-Lp0y",
    "colab_type": "code",
    "outputId": "e199b20c-024e-4056-9fd1-614e321b1945",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426121049,
     "user_tz": -60,
     "elapsed": 29258,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "ExecuteTime": {
     "end_time": "2024-12-30T19:05:03.143524200Z",
     "start_time": "2024-12-30T19:05:03.141975Z"
    }
   },
   "source": [
    "if not os.path.exists(SUBJECT_TRAIN_FILE_PATH):\n",
    "    print(\"Missing file: {}\".format(SUBJECT_TRAIN_FILE_PATH))\n",
    "else:\n",
    "    # Load the required data\n",
    "    data = loadmat(SUBJECT_TRAIN_FILE_PATH)\n",
    "    # Get the variables of interest from the loaded dictionary\n",
    "    signals = data['Signal']\n",
    "    # Take only the 8 selected channels of the signal\n",
    "    signals = signals[:, :, CHANNELS]\n",
    "    \n",
    "    flashing = data['Flashing']\n",
    "    stimulus = data['StimulusType']\n",
    "    word = data['TargetChar']\n",
    "    \n",
    "    SAMPLING_FREQUENCY = 240\n",
    "    # From the dataset description we know that there are 15 repetitions\n",
    "    REPETITIONS = 15\n",
    "    # Compute the duration of the recording in minutes\n",
    "    RECORDING_DURATION = (len(signals))*(len(signals[0]))/(SAMPLING_FREQUENCY*60)\n",
    "    # Compute number of trials\n",
    "    TRIALS = len(word[0])\n",
    "    # Set flag to True to balance the training set\n",
    "    BALANCE_DATASET = False\n",
    "\n",
    "    print(\"**********************************\")\n",
    "    print(\"       TRAIN SET INFORMATION      \")\n",
    "    print(\"**********************************\")\n",
    "    print(\"Sampling Frequency: %d Hz [%.2f ms]\" % (SAMPLING_FREQUENCY, (1000/SAMPLING_FREQUENCY)))\n",
    "    print(\"Session duration:   %.2f min\" % RECORDING_DURATION)\n",
    "    print(\"Number of letters:  %d\" % TRIALS)\n",
    "    print(\"Spelled word:       %s\" % ''.join(word))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IXuVC7puKcLt",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.143524200Z"
    }
   },
   "source": [
    "# Application of butterworth filter\n",
    "b, a = signal.butter(4, [0.1/SAMPLING_FREQUENCY, 20/SAMPLING_FREQUENCY], 'bandpass')\n",
    "for trial in range(TRIALS):\n",
    "    signals[trial, :, :] = signal.filtfilt(b, a, signals[trial, :, :], axis=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jS1FuKDuixnF",
    "colab_type": "code",
    "outputId": "a19bb4fb-6a4b-4b44-ba44-7f729431d9cb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426121353,
     "user_tz": -60,
     "elapsed": 29535,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "ExecuteTime": {
     "end_time": "2024-12-30T19:05:03.147531Z",
     "start_time": "2024-12-30T19:05:03.146532Z"
    }
   },
   "source": [
    "# Down-sampling of the signals from 240Hz to 120Hz\n",
    "DOWNSAMPLING_FREQUENCY = 120\n",
    "SCALE_FACTOR = round(SAMPLING_FREQUENCY / DOWNSAMPLING_FREQUENCY)\n",
    "SAMPLING_FREQUENCY = DOWNSAMPLING_FREQUENCY\n",
    "\n",
    "print(\"# Samples of EEG signals before downsampling: {}\".format(len(signals[0])))\n",
    "\n",
    "signals = signals[:, 0:-1:SCALE_FACTOR, :]\n",
    "flashing = flashing[:, 0:-1:SCALE_FACTOR]\n",
    "stimulus = stimulus[:, 0:-1:SCALE_FACTOR]\n",
    "\n",
    "print(\"# Samples of EEG signals after downsampling: {}\".format(len(signals[0])))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bGaRKwu9MIvP",
    "colab_type": "code",
    "outputId": "3811eb93-0287-45ca-c7dc-4983d900ecd5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426122926,
     "user_tz": -60,
     "elapsed": 31095,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "ExecuteTime": {
     "end_time": "2024-12-30T19:05:03.160053800Z",
     "start_time": "2024-12-30T19:05:03.149529900Z"
    }
   },
   "source": [
    "# Number of EEG channels\n",
    "N_CHANNELS = 8\n",
    "# Window duration after each flashing [ms]\n",
    "WINDOW_DURATION = 650\n",
    "# Number of samples of each window\n",
    "WINDOW_SAMPLES = round(SAMPLING_FREQUENCY * (WINDOW_DURATION / 1000))\n",
    "# Number of samples for each character in trials\n",
    "SAMPLES_PER_TRIAL = len(signals[0])\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "\n",
    "for trial in range(TRIALS):\n",
    "    for sample in (range(SAMPLES_PER_TRIAL)):\n",
    "        if (sample == 0) or (flashing[trial, sample-1] == 0 and flashing[trial, sample] == 1):\n",
    "            lower_sample = sample\n",
    "            upper_sample = sample + WINDOW_SAMPLES\n",
    "            window = signals[trial, lower_sample:upper_sample, :]                \n",
    "            # Features extraction\n",
    "            train_features.append(window)\n",
    "            # Labels extraction\n",
    "            if stimulus[trial, sample] == 1:\n",
    "                count_positive += 1\n",
    "                train_labels.append(1) # Class P300\n",
    "            else:\n",
    "                count_negative += 1\n",
    "                train_labels.append(0) # Class no-P300\n",
    "\n",
    "# Get negative-positive classes ratio\n",
    "train_ratio = count_negative/count_positive\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# 3D Tensor shape (SAMPLES, 78, 8)\n",
    "dim_train = train_features.shape\n",
    "print(\"Features tensor shape: {}\".format(dim_train))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kKMlV1Mqapew",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.151038500Z"
    }
   },
   "source": [
    "# Data normalization Zi = (Xi - mu) / sigma\n",
    "for pattern in range(len(train_features)):\n",
    "    train_features[pattern] = scale(train_features[pattern], axis=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTVrfKzJH2aE",
    "colab_type": "text"
   },
   "source": [
    "# Testing set processing\n",
    "\n",
    "1.   Application of bandpass filter **(0.1-20Hz)**;\n",
    "2.   Down-sampling signas from 240Hz to 120Hz;\n",
    "3.   Obtain windows of 650ms at the start of every flashing (175ms)\n",
    "4.   Normalization of samples in each window: **Zi = (Xi - mu) / sigma**;\n",
    "5.   Reshape each window to be a 3D tensor with dimensions: **(N_SAMPLES, 78, N_CHANNELS)**;\n",
    "6.   Calculate weights vector to balance samples importance and obtain correct accuracy estimation;"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nm-bZZsKTliz",
    "colab_type": "code",
    "outputId": "377bce66-9fc9-4587-fc47-1921b8ba20f5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426130954,
     "user_tz": -60,
     "elapsed": 39099,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.154046400Z"
    }
   },
   "source": [
    "# Test data loading\n",
    "if not os.path.exists(SUBJECT_TEST_FILE_PATH):\n",
    "    print(\"Missing file: {}\", SUBJECT_TEST_FILE_PATH)\n",
    "else:\n",
    "    # Load the required data\n",
    "    data_test = loadmat(SUBJECT_TEST_FILE_PATH)\n",
    "    # Get the variables of interest from the loaded dictionary\n",
    "    signals_test = data_test['Signal']\n",
    "    signals_test = signals_test[:, :, CHANNELS]\n",
    "    flashing_test = data_test['Flashing']\n",
    "    word_test =  data_test['TargetChar']\n",
    "    stimulus_code_test = data_test['StimulusCode']\n",
    "\n",
    "    SAMPLING_FREQUENCY = 240\n",
    "    # From the dataset description we know that there are 15 repetitions\n",
    "    REPETITIONS = 15\n",
    "    # Compute the duration of the recording in minutes\n",
    "    RECORDING_DURATION_TEST = (len(signals_test))*(len(signals_test[0]))/(SAMPLING_FREQUENCY*60)\n",
    "    # Compute number of trials\n",
    "    TRIALS_TEST = len(word_test[0])\n",
    "    # Number of samples for each character in trials\n",
    "    SAMPLES_PER_TRIAL_TEST = len(signals_test[0])\n",
    "    \n",
    "    print(\"**********************************\")\n",
    "    print(\"        TEST SET INFORMATION      \")\n",
    "    print(\"**********************************\")\n",
    "    print(\"Sampling Frequency: %d Hz [%.2f ms]\" % (SAMPLING_FREQUENCY, (1000/SAMPLING_FREQUENCY)))\n",
    "    print(\"Session duration:   %.2f min\" % RECORDING_DURATION_TEST)\n",
    "    print(\"Number of letters:  %d\" % TRIALS_TEST)\n",
    "    print(\"Spelled word:       %s\" % ''.join(word_test))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SvCresQJm25A",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.155045300Z"
    }
   },
   "source": [
    "# Create characters matrix\n",
    "char_matrix = [[0 for j in range(6)] for i in range(6)]\n",
    "s = string.ascii_uppercase + '1' + '2' + '3' + '4' + '5' + '6' + '7' + '8' + '9' + '_'\n",
    "\n",
    "# Append cols and rows in a list\n",
    "list_matrix = []\n",
    "for i in range(6):\n",
    "    col = [s[j] for j in range(i, 36, 6)]\n",
    "    list_matrix.append(col)\n",
    "for i in range(6):\n",
    "    row = [s[j] for j in range(i * 6, i * 6 + 6)]\n",
    "    list_matrix.append(row)\n",
    "\n",
    "# Create StimulusType array for the test set (missing from the given database)\n",
    "stimulus_test = [[0 for j in range(SAMPLES_PER_TRIAL_TEST)] for i in range(TRIALS_TEST)]\n",
    "stimulus_test = np.array(stimulus_test)\n",
    "\n",
    "for trial in range(TRIALS_TEST):\n",
    "    counter=0\n",
    "    for sample in range(SAMPLES_PER_TRIAL_TEST):\n",
    "        index = int(stimulus_code_test[trial, sample]) - 1\n",
    "        if not index == -1:\n",
    "            if word_test[0][trial] in list_matrix[index]:\n",
    "                stimulus_test[trial, sample] = 1\n",
    "            else:\n",
    "                stimulus_test[trial, sample] = 0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UNy5oI8ooMAw",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.158050600Z"
    }
   },
   "source": [
    "# Application of butterworth filter\n",
    "b, a = signal.butter(4, [0.1/SAMPLING_FREQUENCY, 20/SAMPLING_FREQUENCY], 'bandpass')\n",
    "for trial in range(TRIALS_TEST):\n",
    "    signals_test[trial, :, :] = signal.filtfilt(b, a, signals_test[trial, :, :], axis=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8CpKeth5qOjr",
    "colab_type": "code",
    "outputId": "241a49a6-0ae9-4691-a35a-4422b5671d5e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426132039,
     "user_tz": -60,
     "elapsed": 40139,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.160053800Z"
    }
   },
   "source": [
    "# Down-sampling of the signals from 240Hz to 120Hz\n",
    "DOWNSAMPLING_FREQUENCY = 120\n",
    "SCALE_FACTOR = round(SAMPLING_FREQUENCY / DOWNSAMPLING_FREQUENCY)\n",
    "SAMPLING_FREQUENCY = DOWNSAMPLING_FREQUENCY\n",
    "\n",
    "print(\"# Samples of EEG signals before downsampling: {}\".format(len(signals_test[0])))\n",
    "\n",
    "signals_test = signals_test[:, 0:-1:SCALE_FACTOR, :]\n",
    "flashing_test = flashing_test[:, 0:-1:SCALE_FACTOR]\n",
    "stimulus_test = stimulus_test[:, 0:-1:SCALE_FACTOR]\n",
    "\n",
    "print(\"# Samples of EEG signals after downsampling: {}\".format(len(signals_test[0])))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "48sta55OVXFy",
    "colab_type": "code",
    "outputId": "918c5a3c-2b95-45a9-e6fe-9a9f24f7fd81",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426133421,
     "user_tz": -60,
     "elapsed": 41506,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "ExecuteTime": {
     "end_time": "2024-12-30T19:05:03.220938600Z",
     "start_time": "2024-12-30T19:05:03.161050Z"
    }
   },
   "source": [
    "# Number of EEG channels\n",
    "N_CHANNELS = len(CHANNELS)\n",
    "# Window duration after each flashing [ms]\n",
    "WINDOW_DURATION = 650\n",
    "# Number of samples of each window\n",
    "WINDOW_SAMPLES = round(SAMPLING_FREQUENCY * (WINDOW_DURATION / 1000))\n",
    "# Number of samples for each character in trials\n",
    "SAMPLES_PER_TRIAL_TEST = len(signals[0])\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "windowed_stimulus = []\n",
    "\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "\n",
    "for trial in range(TRIALS_TEST):\n",
    "    for sample in (range(SAMPLES_PER_TRIAL_TEST)):\n",
    "        if (sample == 0) or (flashing_test[trial, sample-1] == 0 and flashing_test[trial, sample] == 1):\n",
    "            lower_sample = sample\n",
    "            upper_sample = sample + WINDOW_SAMPLES\n",
    "            window = signals_test[trial, lower_sample:upper_sample, :]\n",
    "            # Extracting number of row/col in a window\n",
    "            number_stimulus = int(stimulus_code_test[trial, sample])\n",
    "            windowed_stimulus.append(number_stimulus)\n",
    "            # Features extraction\n",
    "            test_features.append(window)\n",
    "            # Labels extraction\n",
    "            if stimulus_test[trial, sample] == 1:\n",
    "                count_positive += 1\n",
    "                test_labels.append(1) # Class P300\n",
    "            else:\n",
    "                count_negative += 1\n",
    "                test_labels.append(0) # Class no-P300\n",
    "\n",
    "# Get test weights to take into account the number of classes \n",
    "test_weights = []\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 1:\n",
    "        test_weights.append(len(test_labels)/count_positive)\n",
    "    else:\n",
    "        test_weights.append(len(test_labels)/count_negative)\n",
    "test_weights = np.array(test_weights)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# 3D tensor (SAMPLES, 78, 64)\n",
    "dim_test = test_features.shape\n",
    "print(\"Features tensor shape: {}\".format(dim_test))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-VY8Nr04YI9F",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.162185500Z"
    }
   },
   "source": [
    "# Data normalization Zi = (Xi - mu) / sigma\n",
    "for pattern in range(len(test_features)):\n",
    "    test_features[pattern] = scale(test_features[pattern], axis=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VK4MFXTjHoM",
    "colab_type": "text"
   },
   "source": [
    "# CNN2c model definition, training and testing\n",
    "\n",
    "1.   Function definiton for randomization of weights and biases;\n",
    "2.   **Scaled_tanh(x)** activation function definition;\n",
    "3.   ANN model definition (2 Conv1D layers, 2 dense layers);\n",
    "4.   Training of the network over weighted dataset;\n",
    "5.   CNN2c performance assessment;"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eTIc_w_TcOmK",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.164189200Z"
    }
   },
   "source": [
    "# Randomizing function for bias and weights of the network\n",
    "def cecotti_normal(shape, dtype = None, partition_info = None):\n",
    "    if len(shape) == 1:\n",
    "        fan_in = shape[0]\n",
    "    elif len(shape) == 2:\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        receptive_field_size = 1\n",
    "        for dim in shape[:-2]:\n",
    "            receptive_field_size *= dim\n",
    "        fan_in = shape[-2] * receptive_field_size\n",
    "    return K.random_normal(shape, mean = 0.0, stddev = (1.0 / fan_in))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VeyyvqGgcTsa",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.166185300Z"
    }
   },
   "source": [
    "# Custom tanh activation function\n",
    "def scaled_tanh(z):\n",
    "    return 1.7159 * K.tanh((2.0 / 3.0) * z)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BuMCOgJ3ST-h",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.167188900Z"
    }
   },
   "source": [
    "# Build the model\n",
    "def CNN2c_model(channels=N_CHANNELS, filters=10):\n",
    "    model = Sequential([\n",
    "        Conv1D(\n",
    "            filters = filters,\n",
    "            kernel_size = 1,\n",
    "            padding = \"same\",\n",
    "            bias_initializer = cecotti_normal,\n",
    "            kernel_initializer = cecotti_normal,\n",
    "            use_bias = True,\n",
    "            activation = scaled_tanh,\n",
    "            input_shape = (78, channels)\n",
    "        ),\n",
    "        Conv1D(\n",
    "            filters = 50,\n",
    "            kernel_size = 13,\n",
    "            padding = \"valid\",\n",
    "            strides = 11,\n",
    "            bias_initializer = cecotti_normal,\n",
    "            kernel_initializer = cecotti_normal,\n",
    "            use_bias = True,\n",
    "            activation = scaled_tanh,\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(100, activation=\"sigmoid\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    return model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jVMdFs4quaZL",
    "colab_type": "code",
    "outputId": "9e9f5f4e-d892-4751-e485-0156b444b202",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426140240,
     "user_tz": -60,
     "elapsed": 48258,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.170190800Z"
    }
   },
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 200\n",
    "VALID_SPLIT = 0.05\n",
    "SHUFFLE = 1 # set to 1 to shuffle subsets during training\n",
    "\n",
    "# Model summary\n",
    "CNN2c_model(channels=N_CHANNELS, filters=10).summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GEPpgyxyTl-u",
    "colab_type": "code",
    "outputId": "c6f258b6-69d9-4dbf-e8b3-94b4bd07e276",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426172008,
     "user_tz": -60,
     "elapsed": 80012,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.172723200Z"
    }
   },
   "source": [
    "# Model definition\n",
    "model = CNN2c_model(channels=N_CHANNELS, filters=10)\n",
    "\n",
    "# Callback to save best model only\n",
    "checkpoint = ModelCheckpoint(filepath=MODEL_LOCATIONS_FILE_PATH +  \"/model\" + ELECTRODE_SELECTED + \".h5\", \n",
    "                             monitor='val_loss', \n",
    "                             mode='min',\n",
    "                             save_best_only=True)\n",
    "\n",
    "# Callback to stop when loss on validation set doesn't decrease in 50 epochs\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                              mode = 'min', \n",
    "                              patience = 50, \n",
    "                              restore_best_weights = True)\n",
    "\n",
    "# Callback to keep track of model statistics\n",
    "history = model.fit(x=train_features, \n",
    "                    y=train_labels, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_split=VALID_SPLIT, \n",
    "                    callbacks=[checkpoint, earlystop],\n",
    "                    shuffle=SHUFFLE,\n",
    "                    class_weight={0: 1., 1: train_ratio})"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eJHaj2f1VFYZ",
    "colab_type": "code",
    "outputId": "52053b60-0d1b-473d-87a0-7f0f59b490a9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426172929,
     "user_tz": -60,
     "elapsed": 80925,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.173722700Z"
    }
   },
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "# Plots of loss curves during training\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label=\"training loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plots of accuracy curves during training\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['acc'], label=\"training accuracy\")\n",
    "plt.plot(history.history['val_acc'], label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sg1zrX0xZTRt",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.176242500Z"
    }
   },
   "source": [
    "# Define model\n",
    "best_model = CNN2c_model(channels=N_CHANNELS, filters=10)\n",
    "\n",
    "# Load best model weights from h5 file\n",
    "best_model.load_weights(MODEL_LOCATIONS_FILE_PATH + \"/model\" + ELECTRODE_SELECTED + \".h5\")\n",
    "\n",
    "# Compile best model model\n",
    "best_model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_j_iqu0tYlbS",
    "colab_type": "code",
    "outputId": "86aad8dd-9829-4688-a5bc-806873128295",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426175556,
     "user_tz": -60,
     "elapsed": 83528,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.179243600Z"
    }
   },
   "source": [
    "# Load topoplot coordinates\n",
    "if not os.path.exists(CHANNEL_COORD):\n",
    "    print(\"Missing file: {}\".format(CHANNEL_COORD))\n",
    "else:\n",
    "    xycoord = []\n",
    "    # Read file content\n",
    "    with open(CHANNEL_COORD, \"r\") as f:\n",
    "        file_content = f.read()\n",
    "        # Loop over all rows\n",
    "        for row in file_content.split(\"\\n\"): \n",
    "        # Skip missing rows\n",
    "            if row == '':\n",
    "                continue\n",
    "            xycoord.append(row)\n",
    "\n",
    "# Create a list with x,y coordinates of each electrodes well formatted\n",
    "coord = []\n",
    "for x in xycoord:\n",
    "    coord.append(x.split(','))\n",
    "coord = np.array(coord)\n",
    "\n",
    "# Flip y axis in order to plot in the right way the electrodes positions\n",
    "for i in range(len(coord)):\n",
    "    coord[i][1] = 681 -int(coord[i][1])\n",
    "\n",
    "# Create a list of weights for all filters\n",
    "nf = []\n",
    "for filt in range(10):\n",
    "    nf.append(abs(np.array(best_model.get_weights()[0])[0, :, filt]))\n",
    "nf = np.array(nf, dtype=float)\n",
    "\n",
    "# Add -1 to missing channels values\n",
    "tmp_full = []\n",
    "for i in range(10):\n",
    "    tmp = np.full(64, 0, dtype=float)\n",
    "    for c in range(N_CHANNELS):\n",
    "        tmp[CHANNELS[c]] = nf[i][c]\n",
    "    tmp_full.append(tmp)\n",
    "nf = np.array(tmp_full, dtype=float)\n",
    "\n",
    "# Plot topoplot of the 10 filters in the first convolutional layer\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2,5,i+1)\n",
    "    ax.set_title(\"Filter #{}\".format(i+1))\n",
    "    mne.viz.plot_topomap(nf[i], coord, cmap='Spectral_r', axes=ax, show=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EzbVkDAwUmfa",
    "colab_type": "code",
    "outputId": "ca5312d0-c969-4c7e-d88d-8f98f889d5ee",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426176170,
     "user_tz": -60,
     "elapsed": 84124,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.181239800Z"
    }
   },
   "source": [
    "# Accuracy over the testing set\n",
    "predictions = best_model.predict(test_features)\n",
    "predictions = np.round(predictions)\n",
    "\n",
    "score = np.array(best_model.evaluate(test_features, test_labels, verbose=0, sample_weight=test_weights))\n",
    "print(\"Model performance on test set:\\t[ Loss: {}\\tAccuracy: {} ]\".format(*score.round(4)))\n",
    "print(\"\\nPredictions: {}\\nSolutions:   {}\".format(list(map(int, predictions))[:50], list(map(int, test_labels))[:50]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DVKxqyKZpyg8",
    "colab_type": "code",
    "outputId": "976a8aed-3806-4fae-a569-a0af6894ebe0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426176733,
     "user_tz": -60,
     "elapsed": 84674,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.182635Z"
    }
   },
   "source": [
    "# Weighted confusion matrix (noP300: 80%, P300: 20%)\n",
    "data = confusion_matrix(y_true=test_labels, y_pred=predictions, sample_weight=test_weights)\n",
    "\n",
    "# Normalized confusion matrix (values in range 0-1)\n",
    "data_norm = data/np.full(data.shape, len(test_labels))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "df_cm = pd.DataFrame(data_norm, columns=np.unique(test_labels), index = np.unique(test_labels))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (6,5))\n",
    "sns.set(font_scale = 1.4)\n",
    "cm = sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws = {\"size\": 16}, vmin=0, vmax=1)\n",
    "cm.axes.set_title(\"CNN2a confusion matrix\\n\", fontsize=20)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JUPsdxe4qrqi",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.184628200Z"
    }
   },
   "source": [
    "# Model metrics (sens, spec, ppv, npv)\n",
    "def model_metrics(conf_matrix):\n",
    "    tn, fp, fn, tp = list(data_norm.flatten())\n",
    "    sens = round(tp/(tp+fn),4) # Sensitivity\n",
    "    spec = round(tn/(tn+fp),4) # Specificity\n",
    "    ppv = round(tp/(tp+fp),4) # Positive Predicted Value\n",
    "    npv = round(tn/(tn+fn),4) # Negative Predicted Value\n",
    "    return {\"Sensitivity\":sens, \"Specificity\":spec, \"PPV\":ppv, \"NPV\":npv}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yo3CmAb2qrt6",
    "colab_type": "code",
    "outputId": "242b6cb7-0602-4515-d8a9-0e37c4ec166d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1576426176735,
     "user_tz": -60,
     "elapsed": 84647,
     "user": {
      "displayName": "Lorenzo Gualniera",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCLpjQsro-Xs6X0aZX_0HuLLblFWB6HZFMeyZLy=s64",
      "userId": "15976103540540623653"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "ExecuteTime": {
     "start_time": "2024-12-30T19:05:03.185639Z"
    }
   },
   "source": [
    "# Put model metrics into a table\n",
    "metrics = model_metrics(data_norm)\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(5,1))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Hide graph outlines\n",
    "for item in [fig, ax]:\n",
    "    item.patch.set_visible(False)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Table definition\n",
    "table = ax.table(cellText=[list(metrics.values())], \n",
    "                     colLabels=list(metrics.keys()),\n",
    "                     loc=\"center\",\n",
    "                     cellLoc=\"center\",\n",
    "                     colColours=[\"c\"]*4)\n",
    "table.set_fontsize(16)\n",
    "table.scale(2,2)\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
